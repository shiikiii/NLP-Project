{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSO 560 Project Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "The goal of this projecct to predict tags of different categories for all the clothing products. The categories we chose are `Style`, `Occassion` and `Category`. And the target texts we decided to focus on are `brand`, `product_full_name`, `brand_category`, `details`, and `description`.\n",
    "\n",
    "How we approached the problem: First of all, we did text cleaning and preprocessing. Then we tried different models (methods) and compared their performances to make sure we're landing on the best model. The codes for all the models we tried will be appended at last. Finally, we chose the best model and compiled everything together to make the model user-friendly.\n",
    "\n",
    "As a result, LSTM turned out to be the best model and we implemented it on all the categories we chose (Part III Modelling). The LSTM for category reached 96.09% accuracy and 99.48% AUROC (super good). For style and occasion, we did 10-fold cross validation wrapped in 3-time calculation for more accurate accuracy and AUROC. Our final LSTM model for style reached 74.11% - 89.71% accuracy and 79.82% - 94.11% AUROC and the LSTM for occassion reached 71.23% - 86.42% accuracy and 72.69% - 92.31% AUROC.\n",
    "\n",
    "The output of this project are an Excel worksheet with all the products tagged, a Github repository with all codes and an instruction for prediction in Part IV for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### [I. Load Data](#1)\n",
    "### [II. Text Preprocessing](#2)\n",
    "### [III. Model Performances](#3)\n",
    "[Performance 1: LSTM for all styles](#31)\n",
    "    \n",
    "[Performance 2: LSTM for all occassions](#32)\n",
    "   \n",
    "[Performance 3: LSTM for all categories](#33)\n",
    "\n",
    "### [IV. Prediction](#4)\n",
    "[Prediction 1: Style](#41)\n",
    "    \n",
    "[Prediction 2: Ocassion](#42)\n",
    "   \n",
    "[Prediction 3: Category](#43)\n",
    "\n",
    "### [V. Appendix](#5)\n",
    "[1. LSTM Algorithm Exploration & Parameter Tuning](#51)\n",
    "\n",
    "[2. Neural Net Exploration](#52)\n",
    "\n",
    "[3. Pre-trained Word Embedding & TF-IDF](#53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import sklearn\n",
    "import spacy\n",
    "import gensim \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '1'></a>\n",
    "\n",
    "# I. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"threadtogether\", user=\"dso_student\", password=\"-H4jgA`rn6w`=Jg(\", host=\"threadtogether.ychennay.com\", port=\"5432\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all the tables\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select *  \n",
    "                            from information_schema.tables\n",
    "                            where table_schema='public'\"\"\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>self_referencing_column_name</th>\n",
       "      <th>reference_generation</th>\n",
       "      <th>user_defined_type_catalog</th>\n",
       "      <th>user_defined_type_schema</th>\n",
       "      <th>user_defined_type_name</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>commit_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>full_data</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>womens_clothing_reviews</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>tagged_product_attributes</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>categories</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>outfits</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threadtogether</td>\n",
       "      <td>public</td>\n",
       "      <td>outfit_combinations</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    table_catalog table_schema                 table_name  table_type  \\\n",
       "0  threadtogether       public                  full_data  BASE TABLE   \n",
       "1  threadtogether       public    womens_clothing_reviews  BASE TABLE   \n",
       "2  threadtogether       public  tagged_product_attributes  BASE TABLE   \n",
       "3  threadtogether       public                 categories  BASE TABLE   \n",
       "4  threadtogether       public                    outfits  BASE TABLE   \n",
       "5  threadtogether       public        outfit_combinations        VIEW   \n",
       "\n",
       "  self_referencing_column_name reference_generation user_defined_type_catalog  \\\n",
       "0                         None                 None                      None   \n",
       "1                         None                 None                      None   \n",
       "2                         None                 None                      None   \n",
       "3                         None                 None                      None   \n",
       "4                         None                 None                      None   \n",
       "5                         None                 None                      None   \n",
       "\n",
       "  user_defined_type_schema user_defined_type_name is_insertable_into is_typed  \\\n",
       "0                     None                   None                YES       NO   \n",
       "1                     None                   None                YES       NO   \n",
       "2                     None                   None                YES       NO   \n",
       "3                     None                   None                YES       NO   \n",
       "4                     None                   None                YES       NO   \n",
       "5                     None                   None                 NO       NO   \n",
       "\n",
       "  commit_action  \n",
       "0          None  \n",
       "1          None  \n",
       "2          None  \n",
       "3          None  \n",
       "4          None  \n",
       "5          None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=[desc[0] for desc in cur.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from full_data\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from full_data\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection\\nCase and cleaning cloth in...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper\\nRound toe\\nLace-up vamp\\nSmartFO...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection\\nGradient lenses\\nAdjustabl...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection\\nCase and cleaning cloth in...  {\"Needs Review\"}   \n",
       "3  Canvas upper\\nRound toe\\nLace-up vamp\\nSmartFO...  {\"Needs Review\"}   \n",
       "4  100% UV protection\\nGradient lenses\\nAdjustabl...  {\"Needs Review\"}   \n",
       "\n",
       "  bc_product_id  \n",
       "0          NULL  \n",
       "1          NULL  \n",
       "2          NULL  \n",
       "3          NULL  \n",
       "4          NULL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48979 entries, 0 to 48978\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   product_id           48979 non-null  object\n",
      " 1   brand                48979 non-null  object\n",
      " 2   mpn                  48979 non-null  object\n",
      " 3   product_full_name    48979 non-null  object\n",
      " 4   description          41005 non-null  object\n",
      " 5   brand_category       48741 non-null  object\n",
      " 6   created_at           48979 non-null  object\n",
      " 7   updated_at           48979 non-null  object\n",
      " 8   deleted_at           45984 non-null  object\n",
      " 9   brand_canonical_url  48967 non-null  object\n",
      " 10  details              47950 non-null  object\n",
      " 11  labels               48979 non-null  object\n",
      " 12  bc_product_id        48979 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from tagged_product_attributes\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from tagged_product_attributes\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DVBTBPHR8WJTCVEN5AJRHF47</td>\n",
       "      <td>01DVBTBPJ41VVT00JJCG8TTZ2W</td>\n",
       "      <td>gender</td>\n",
       "      <td>Women</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVA7QRXM928ZM0WWR7HFNTC1</td>\n",
       "      <td>01DVA7QRXXR9F0TWVE1HMC5ZQ3</td>\n",
       "      <td>Primary Color</td>\n",
       "      <td>Blacks</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>01DPGVGBK6YGNYGNF2S6FSH02T</td>\n",
       "      <td>style</td>\n",
       "      <td>Casual</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01E1JM43NQ3H17PB22EV3074NX</td>\n",
       "      <td>01E1JM5WFWWCCCH3JTTTCYQCEQ</td>\n",
       "      <td>style</td>\n",
       "      <td>Modern</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>01DSE8ZG8Y3FR8KWE2TY1QDWBF</td>\n",
       "      <td>shoe_width</td>\n",
       "      <td>Medium</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            product_color_id attribute_name  \\\n",
       "0  01DVBTBPHR8WJTCVEN5AJRHF47  01DVBTBPJ41VVT00JJCG8TTZ2W         gender   \n",
       "1  01DVA7QRXM928ZM0WWR7HFNTC1  01DVA7QRXXR9F0TWVE1HMC5ZQ3  Primary Color   \n",
       "2  01DPGV4YRP3Z8J85DASGZ1Y99W  01DPGVGBK6YGNYGNF2S6FSH02T          style   \n",
       "3  01E1JM43NQ3H17PB22EV3074NX  01E1JM5WFWWCCCH3JTTTCYQCEQ          style   \n",
       "4  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  01DSE8ZG8Y3FR8KWE2TY1QDWBF     shoe_width   \n",
       "\n",
       "  attribute_value          file  \n",
       "0           Women  initial_tags  \n",
       "1          Blacks  initial_tags  \n",
       "2          Casual  initial_tags  \n",
       "3          Modern  initial_tags  \n",
       "4          Medium  initial_tags  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])\n",
    "tagged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119345 entries, 0 to 119344\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   product_id        119345 non-null  object\n",
      " 1   product_color_id  119345 non-null  object\n",
      " 2   attribute_name    119345 non-null  object\n",
      " 3   attribute_value   119345 non-null  object\n",
      " 4   file              119345 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tagged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from womens_clothing_reviews\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from womens_clothing_reviews\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend</th>\n",
       "      <th>likes</th>\n",
       "      <th>division</th>\n",
       "      <th>department</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>None</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  age                    title  \\\n",
       "0          767   33                     None   \n",
       "1         1080   34                     None   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         review_text  rating  recommend  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4          1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5          1   \n",
       "2  I had such high hopes for this dress and reall...       3          0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5          1   \n",
       "4  This shirt is very flattering to all due to th...       5          1   \n",
       "\n",
       "   likes        division department      class  \n",
       "0      0       Initmates   Intimate  Intimates  \n",
       "1      4         General    Dresses    Dresses  \n",
       "2      0         General    Dresses    Dresses  \n",
       "3      0  General Petite    Bottoms      Pants  \n",
       "4      6         General       Tops    Blouses  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from categories\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from categories\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>quantifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Androgynous</td>\n",
       "      <td>style</td>\n",
       "      <td>general</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athleisure</td>\n",
       "      <td>style</td>\n",
       "      <td>general</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boho</td>\n",
       "      <td>style</td>\n",
       "      <td>general</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Casual</td>\n",
       "      <td>style</td>\n",
       "      <td>general</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Casual</td>\n",
       "      <td>style</td>\n",
       "      <td>general</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             value category     type quantifier\n",
       "0      Androgynous    style  general       many\n",
       "1       Athleisure    style  general       many\n",
       "2             Boho    style  general       many\n",
       "3  Business Casual    style  general       many\n",
       "4           Casual    style  general       many"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View\n",
    "pd.DataFrame(data, columns=[desc[0] for desc in cur.description]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from outfits\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from outfits\")\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2S83FARJW4QWRBXNS</td>\n",
       "      <td>shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2V2Y8EN8YPY1E16EV</td>\n",
       "      <td>accessory1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA23E5A8GBES8QJN3HF</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2C7BQN0X7MNNYXBHW</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMHCX50CFX5YNG99F3Y65GQW</td>\n",
       "      <td>01DMBRYVA2S83FARJW4QWRBXNS</td>\n",
       "      <td>shoe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outfit_id            product_color_id outfit_item_type\n",
       "0  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2S83FARJW4QWRBXNS             shoe\n",
       "1  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2V2Y8EN8YPY1E16EV       accessory1\n",
       "2  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA23E5A8GBES8QJN3HF              top\n",
       "3  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2C7BQN0X7MNNYXBHW           bottom\n",
       "4  01DMHCX50CFX5YNG99F3Y65GQW  01DMBRYVA2S83FARJW4QWRBXNS             shoe"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View\n",
    "pd.DataFrame(data, columns=[desc[0] for desc in cur.description]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfit = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accessory1', 'accessory2', 'accessory3', 'bottom', 'onepiece',\n",
       "       'shoe', 'top'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outfit['outfit_item_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '2'></a>\n",
    "\n",
    "# II. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>A.L.C.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>Lennox High Waist Cotton &amp; Linen Pants</td>\n",
       "      <td>High-rise trousers tailored from a cool Italia...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>True to size. High rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>linenblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>A.L.C.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>Lennox High Waist Cotton &amp; Linen Pants</td>\n",
       "      <td>High-rise trousers tailored from a cool Italia...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>True to size. High rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>cottonblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>A.L.C.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>Lennox High Waist Cotton &amp; Linen Pants</td>\n",
       "      <td>High-rise trousers tailored from a cool Italia...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>True to size. High rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>style</td>\n",
       "      <td>modern</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id   brand      mpn  \\\n",
       "0  01E5ZXP5H0BTEZT9QD2HRZJ47A  A.L.C.  5529544   \n",
       "1  01E5ZXP5H0BTEZT9QD2HRZJ47A  A.L.C.  5529544   \n",
       "2  01E5ZXP5H0BTEZT9QD2HRZJ47A  A.L.C.  5529544   \n",
       "\n",
       "                        product_full_name  \\\n",
       "0  Lennox High Waist Cotton & Linen Pants   \n",
       "1  Lennox High Waist Cotton & Linen Pants   \n",
       "2  Lennox High Waist Cotton & Linen Pants   \n",
       "\n",
       "                                         description brand_category  \\\n",
       "0  High-rise trousers tailored from a cool Italia...        Unknown   \n",
       "1  High-rise trousers tailored from a cool Italia...        Unknown   \n",
       "2  High-rise trousers tailored from a cool Italia...        Unknown   \n",
       "\n",
       "                         created_at                        updated_at  \\\n",
       "0  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                         deleted_at  \\\n",
       "0  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "1  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "2  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "\n",
       "                                             details labels bc_product_id  \\\n",
       "0  True to size. High rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "1  True to size. High rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "2  True to size. High rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "\n",
       "             product_color_id    attribute_name attribute_value        file  \n",
       "0  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing      linenblend  additional  \n",
       "1  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing     cottonblend  additional  \n",
       "2  01E5ZXP5JCREDC7WJVMWHK5Q40             style          modern  additional  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join full_data and tagged_data. Replace NAs and \\n\n",
    "join_data = full_data.merge(tagged_data, on='product_id')\n",
    "join_data = join_data.replace(np.nan, \"\", regex=True)\n",
    "join_data = join_data.replace(\"\\n\", \"\",regex=True)\n",
    "join_data['attribute_value'].replace(r'\\bbusinesscasual\\b', 'business casual', inplace=True, regex=True)\n",
    "join_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton &amp; linen pants</td>\n",
       "      <td>high-rise trousers tailored from a cool italia...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true to size. high rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>linenblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton &amp; linen pants</td>\n",
       "      <td>high-rise trousers tailored from a cool italia...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true to size. high rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>cottonblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c.</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton &amp; linen pants</td>\n",
       "      <td>high-rise trousers tailored from a cool italia...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true to size. high rise.31\" inseam; 14\" leg op...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>style</td>\n",
       "      <td>modern</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id   brand      mpn  \\\n",
       "0  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c.  5529544   \n",
       "1  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c.  5529544   \n",
       "2  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c.  5529544   \n",
       "\n",
       "                        product_full_name  \\\n",
       "0  lennox high waist cotton & linen pants   \n",
       "1  lennox high waist cotton & linen pants   \n",
       "2  lennox high waist cotton & linen pants   \n",
       "\n",
       "                                         description brand_category  \\\n",
       "0  high-rise trousers tailored from a cool italia...        unknown   \n",
       "1  high-rise trousers tailored from a cool italia...        unknown   \n",
       "2  high-rise trousers tailored from a cool italia...        unknown   \n",
       "\n",
       "                         created_at                        updated_at  \\\n",
       "0  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                         deleted_at  \\\n",
       "0  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "1  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "2  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "\n",
       "                                             details labels bc_product_id  \\\n",
       "0  true to size. high rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "1  true to size. high rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "2  true to size. high rise.31\" inseam; 14\" leg op...     []          5021   \n",
       "\n",
       "             product_color_id    attribute_name attribute_value        file  \n",
       "0  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing      linenblend  additional  \n",
       "1  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing     cottonblend  additional  \n",
       "2  01E5ZXP5JCREDC7WJVMWHK5Q40             style          modern  additional  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower case some target texts\n",
    "columns_list = ['brand','product_full_name','description','brand_category','details',\n",
    "                'attribute_name','attribute_value']\n",
    "for column in columns_list:\n",
    "    join_data[column] = join_data[column].str.lower()\n",
    "join_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton linen pants</td>\n",
       "      <td>high-rise trousers tailored cool italian cotto...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true size high rise.31 inseam 14 leg opening 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>linenblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton linen pants</td>\n",
       "      <td>high-rise trousers tailored cool italian cotto...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true size high rise.31 inseam 14 leg opening 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>materialclothing</td>\n",
       "      <td>cottonblend</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01E5ZXP5H0BTEZT9QD2HRZJ47A</td>\n",
       "      <td>a.l.c</td>\n",
       "      <td>5529544</td>\n",
       "      <td>lennox high waist cotton linen pants</td>\n",
       "      <td>high-rise trousers tailored cool italian cotto...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2020-04-15 21:59:56.695000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>2020-04-17 15:44:57.785000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
       "      <td>true size high rise.31 inseam 14 leg opening 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5021</td>\n",
       "      <td>01E5ZXP5JCREDC7WJVMWHK5Q40</td>\n",
       "      <td>style</td>\n",
       "      <td>modern</td>\n",
       "      <td>additional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  brand      mpn  \\\n",
       "0  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c  5529544   \n",
       "1  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c  5529544   \n",
       "2  01E5ZXP5H0BTEZT9QD2HRZJ47A  a.l.c  5529544   \n",
       "\n",
       "                      product_full_name  \\\n",
       "0  lennox high waist cotton linen pants   \n",
       "1  lennox high waist cotton linen pants   \n",
       "2  lennox high waist cotton linen pants   \n",
       "\n",
       "                                         description brand_category  \\\n",
       "0  high-rise trousers tailored cool italian cotto...        unknown   \n",
       "1  high-rise trousers tailored cool italian cotto...        unknown   \n",
       "2  high-rise trousers tailored cool italian cotto...        unknown   \n",
       "\n",
       "                         created_at                        updated_at  \\\n",
       "0  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-15 21:59:56.695000+00:00  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                         deleted_at  \\\n",
       "0  2020-04-17 15:44:57.785000+00:00   \n",
       "1  2020-04-17 15:44:57.785000+00:00   \n",
       "2  2020-04-17 15:44:57.785000+00:00   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "1  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "2  https://shop.nordstrom.com/s/a-l-c-lennox-high...   \n",
       "\n",
       "                                             details labels bc_product_id  \\\n",
       "0  true size high rise.31 inseam 14 leg opening 1...     []          5021   \n",
       "1  true size high rise.31 inseam 14 leg opening 1...     []          5021   \n",
       "2  true size high rise.31 inseam 14 leg opening 1...     []          5021   \n",
       "\n",
       "             product_color_id    attribute_name attribute_value        file  \n",
       "0  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing      linenblend  additional  \n",
       "1  01E5ZXP5JCREDC7WJVMWHK5Q40  materialclothing     cottonblend  additional  \n",
       "2  01E5ZXP5JCREDC7WJVMWHK5Q40             style          modern  additional  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "columns_list2 = ['brand','product_full_name','description','brand_category','details']\n",
    "nltk_stopwords = set(stopwords.words('english') + [\".\",\",\",\":\",\"''\",\"'s\",\"'\",\"``\",\"(\", \")\",\"]\",\n",
    "                                                   \"-\",\"!\",\"/\",\">\",\"<\",\";\",\"#\",\"...\",\"..\",\"?\",\"--\",\"[\",\"&\"])\n",
    "for column in columns_list2:\n",
    "    join_data[column] = join_data[column].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in nltk_stopwords]))\n",
    "    \n",
    "join_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for column in columns_list2:\n",
    "    join_data[column] = join_data[column].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '3'></a>\n",
    "\n",
    "# III. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.l.c lennox high waist cotton linen pant unknown true size high rise.31 inseam 14 leg opening 12 front rise 15 1/2 back rise size 8 zip fly hook-and-bar closurefront slant pocket back welt pockets67 % cotton 33 % linendry cleanimportedvia c high-rise trouser tailored cool italian cotton-and-linen blend make refreshing addition work wardrobe'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join all the target texts we need into a new column called 'tag_info'\n",
    "join_data['tag_info'] = join_data[['brand','product_full_name','brand_category','details','description']].apply(lambda x: ' '.join(x), axis=1)\n",
    "join_data['tag_info'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '31'></a>\n",
    "\n",
    "## Performance 1: LSTM for all styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this part will take about 24 hours to run, we unfortunately did not finishing running this part. But we can still see from some of the results that this would be a very decent model. If we'd have more time, we'd be happy to present all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25539, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the records with 'style' tagged\n",
    "Style = join_data[join_data['attribute_name']=='style'][['tag_info', 'attribute_value']]\n",
    "Style.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10971, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "Style = join_data[join_data['attribute_name']=='style'][['tag_info', 'attribute_value']].drop_duplicates()\n",
    "Style.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the attribute value for category 'style'\n",
    "stylelist = list(np.unique(Style['attribute_value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index for the dataframe Style\n",
    "Style.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_info</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>androgynous</th>\n",
       "      <th>athleisure</th>\n",
       "      <th>boho</th>\n",
       "      <th>business casual</th>\n",
       "      <th>casual</th>\n",
       "      <th>classic</th>\n",
       "      <th>edgy</th>\n",
       "      <th>glam</th>\n",
       "      <th>modern</th>\n",
       "      <th>retro</th>\n",
       "      <th>romantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant unkn...</td>\n",
       "      <td>modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant unkn...</td>\n",
       "      <td>business casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant unkn...</td>\n",
       "      <td>classic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>classic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>business casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>casual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>androgynous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>a.l.c minelli silk sleeveless top unknown true...</td>\n",
       "      <td>modern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>a.l.c minelli silk sleeveless top unknown true...</td>\n",
       "      <td>boho</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tag_info  attribute_value  \\\n",
       "0  a.l.c lennox high waist cotton linen pant unkn...           modern   \n",
       "1  a.l.c lennox high waist cotton linen pant unkn...  business casual   \n",
       "2  a.l.c lennox high waist cotton linen pant unkn...          classic   \n",
       "3  banana republic mock-neck sweater top unknown ...          classic   \n",
       "4  banana republic mock-neck sweater top unknown ...  business casual   \n",
       "5  simon miller rost belted short unknown true si...           modern   \n",
       "6  simon miller rost belted short unknown true si...           casual   \n",
       "7  simon miller rost belted short unknown true si...      androgynous   \n",
       "8  a.l.c minelli silk sleeveless top unknown true...           modern   \n",
       "9  a.l.c minelli silk sleeveless top unknown true...             boho   \n",
       "\n",
       "   androgynous  athleisure  boho  business casual  casual  classic  edgy  \\\n",
       "0            0           0     0                0       0        0     0   \n",
       "1            0           0     0                1       0        0     0   \n",
       "2            0           0     0                0       0        1     0   \n",
       "3            0           0     0                0       0        1     0   \n",
       "4            0           0     0                1       0        0     0   \n",
       "5            0           0     0                0       0        0     0   \n",
       "6            0           0     0                0       1        0     0   \n",
       "7            1           0     0                0       0        0     0   \n",
       "8            0           0     0                0       0        0     0   \n",
       "9            0           0     1                0       0        0     0   \n",
       "\n",
       "   glam  modern  retro  romantic  \n",
       "0     0       1      0         0  \n",
       "1     0       0      0         0  \n",
       "2     0       0      0         0  \n",
       "3     0       0      0         0  \n",
       "4     0       0      0         0  \n",
       "5     0       1      0         0  \n",
       "6     0       0      0         0  \n",
       "7     0       0      0         0  \n",
       "8     0       1      0         0  \n",
       "9     0       0      0         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies for all attribute values\n",
    "for sty in np.unique(Style['attribute_value']):\n",
    "    Style[sty] = 0\n",
    "    Style[sty][Style['attribute_value']==sty]=1\n",
    "Style.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Import tools for tokenizaton and encoding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from typing import List\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import Keras Toolkit\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import  LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "\n",
    "# Define integer encoder for documents\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# Define max length detection tool\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# Load in GloVe Vectors\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import K-Fold validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['androgynous',\n",
       " 'athleisure',\n",
       " 'boho',\n",
       " 'business casual',\n",
       " 'casual',\n",
       " 'classic',\n",
       " 'edgy',\n",
       " 'glam',\n",
       " 'modern',\n",
       " 'retro',\n",
       " 'romantic']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stylelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the randomness of neural network, we set 3 loops (limited time & resources) to average all the metrics, and within each loop, 10-fold cross-validation is applied. Therefore, totally 3 * 10 = 30 loops for each style to achieve relatively lower variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "androgynous =========================================\n",
      "accuracy: 0.741099\n",
      "precision: 0.657893\n",
      "recall: 0.644889\n",
      "AUROC: 0.798162\n",
      "athleisure =========================================\n",
      "accuracy: 0.897072\n",
      "precision: 0.875992\n",
      "recall: 0.853442\n",
      "AUROC: 0.941067\n",
      "boho =========================================\n",
      "accuracy: 0.757938\n",
      "precision: 0.678114\n",
      "recall: 0.677041\n",
      "AUROC: 0.799809\n",
      "business casual =========================================\n",
      "accuracy: 0.769491\n",
      "precision: 0.697760\n",
      "recall: 0.679328\n",
      "AUROC: 0.826173\n",
      "casual =========================================\n",
      "accuracy: 0.799254\n",
      "precision: 0.854350\n",
      "recall: 0.845050\n",
      "AUROC: 0.852494\n",
      "classic =========================================\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for style in stylelist:\n",
    "    \n",
    "    print(style,'=========================================')\n",
    "    \n",
    "    acclist = []\n",
    "    precisionlist = []\n",
    "    recalllist = []\n",
    "    auclist = []\n",
    "\n",
    "    data = Style.groupby('tag_info').agg(specific_style = pd.NamedAgg(column=style, aggfunc='max')).reset_index()\n",
    "    data1 = data[data['specific_style']==1]\n",
    "    if round(len(data1)*1.7) <= len(data[data['specific_style']==0]):\n",
    "        data2 = data[data['specific_style']==0].sample(round(len(data1)*1.7), random_state=123)\n",
    "        data = pd.concat([data1, data2])\n",
    "\n",
    "    tag_list = list(data['tag_info'])\n",
    "\n",
    "    # Tokenize the Text\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(tag_list)\n",
    "\n",
    "    # get the max length in terms of token length\n",
    "    max_length = get_max_token_length_per_doc(tag_list)\n",
    "\n",
    "    # integer encode the documents\n",
    "    encoded_docs = integer_encode_documents(tag_list, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    labels = data['specific_style']\n",
    "    labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "    X_train = padded_docs\n",
    "    y_train = labels\n",
    "    \n",
    "    VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "    # Load in Embeddings\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    def make_lstm_classification_model(plot=False):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "        model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "        model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "        # model.add(Dense(16))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            plot_model(model, to_file='model.png', show_shapes=True)\n",
    "        return model\n",
    "    \n",
    "    for loop in range(3):\n",
    "        \n",
    "        model = make_lstm_classification_model()\n",
    "        \n",
    "        # k-fold cross validation\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        # enumerate splits\n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "            # split train & test\n",
    "            cross_train_X, cross_test_X = X_train[train_index], X_train[test_index]\n",
    "            cross_train_y, cross_test_y = y_train[train_index], y_train[test_index]\n",
    "            # fit model\n",
    "            model = make_lstm_classification_model()\n",
    "            model.fit(cross_train_X, cross_train_y, epochs=15, verbose=0)\n",
    "            # evaluate model\n",
    "            y_prob = model.predict(cross_test_X) \n",
    "            y_classes = y_prob.argmax(axis=-1)\n",
    "            ytest = [np.argmax(y, axis=None, out=None) for y in cross_test_y]\n",
    "            # acc\n",
    "            acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "            # precision \n",
    "            precision = sklearn.metrics.precision_score(ytest, y_classes)\n",
    "            # recall\n",
    "            recall = sklearn.metrics.recall_score(ytest, y_classes)\n",
    "            # auc\n",
    "            auc = sklearn.metrics.roc_auc_score(ytest, [y[1] for y in y_prob])\n",
    "\n",
    "            acclist.append(acc)\n",
    "            precisionlist.append(precision)\n",
    "            recalllist.append(recall)\n",
    "            auclist.append(auc)\n",
    "\n",
    "    print('accuracy: %f' % np.mean(acclist))\n",
    "    print('precision: %f' % np.mean(precisionlist))\n",
    "    print('recall: %f' % np.mean(recalllist))\n",
    "    print('AUROC: %f' % np.mean(auclist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '32'></a>\n",
    "\n",
    "## Performance 2: LSTM for all occasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21263, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Occasion = join_data[join_data['attribute_name']=='occasion'][['tag_info', 'attribute_value']]\n",
    "Occasion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10428, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Occasion = join_data[join_data['attribute_name']=='occasion'][['tag_info', 'attribute_value']].drop_duplicates()\n",
    "Occasion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasionlist = list(np.unique(Occasion['attribute_value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coldweather',\n",
       " 'day to night',\n",
       " 'daytonight',\n",
       " 'night out',\n",
       " 'nightout',\n",
       " 'vacation',\n",
       " 'weekend',\n",
       " 'work',\n",
       " 'workout']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occasionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occasion.loc[Occasion['attribute_value'] ==   'daytonight', 'attribute_value'] =  'day to night'\n",
    "Occasion.loc[Occasion['attribute_value'] ==   'nightout', 'attribute_value'] =  'night out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasionlist = list(np.unique(Occasion['attribute_value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day to night    3625\n",
       "weekend         3083\n",
       "work            1388\n",
       "night out       1247\n",
       "vacation         685\n",
       "coldweather      242\n",
       "workout          158\n",
       "Name: attribute_value, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Occasion['attribute_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occasion.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_info</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>coldweather</th>\n",
       "      <th>day to night</th>\n",
       "      <th>night out</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a.l.c lennox high waist cotton linen pant unkn...</td>\n",
       "      <td>work</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>day to night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>work</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>day to night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>vacation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a.l.c minelli silk sleeveless top unknown true...</td>\n",
       "      <td>day to night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a.l.c minelli silk sleeveless top unknown true...</td>\n",
       "      <td>vacation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>simon miller nepa mismatched button rib cardig...</td>\n",
       "      <td>day to night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>simon miller nepa mismatched button rib cardig...</td>\n",
       "      <td>vacation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tag_info attribute_value  \\\n",
       "0  a.l.c lennox high waist cotton linen pant unkn...            work   \n",
       "1  banana republic mock-neck sweater top unknown ...    day to night   \n",
       "2  banana republic mock-neck sweater top unknown ...            work   \n",
       "3  banana republic mock-neck sweater top unknown ...    day to night   \n",
       "4  simon miller rost belted short unknown true si...         weekend   \n",
       "5  simon miller rost belted short unknown true si...        vacation   \n",
       "6  a.l.c minelli silk sleeveless top unknown true...    day to night   \n",
       "7  a.l.c minelli silk sleeveless top unknown true...        vacation   \n",
       "8  simon miller nepa mismatched button rib cardig...    day to night   \n",
       "9  simon miller nepa mismatched button rib cardig...        vacation   \n",
       "\n",
       "   coldweather  day to night  night out  vacation  weekend  work  workout  \n",
       "0            0             0          0         0        0     1        0  \n",
       "1            0             1          0         0        0     0        0  \n",
       "2            0             0          0         0        0     1        0  \n",
       "3            0             1          0         0        0     0        0  \n",
       "4            0             0          0         0        1     0        0  \n",
       "5            0             0          0         1        0     0        0  \n",
       "6            0             1          0         0        0     0        0  \n",
       "7            0             0          0         1        0     0        0  \n",
       "8            0             1          0         0        0     0        0  \n",
       "9            0             0          0         1        0     0        0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "for occ in np.unique(Occasion['attribute_value']):\n",
    "    Occasion[occ] = 0\n",
    "    Occasion[occ][Occasion['attribute_value']==occ]=1\n",
    "Occasion.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Import tools for tokenizaton and encoding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from typing import List\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import Keras Toolkit\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import  LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "\n",
    "# Define integer encoder for documents\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# Define max length detection tool\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# Load in GloVe Vectors\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import K-Fold validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coldweather',\n",
       " 'day to night',\n",
       " 'night out',\n",
       " 'vacation',\n",
       " 'weekend',\n",
       " 'work',\n",
       " 'workout']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occasionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coldweather =========================================\n",
      "WARNING:tensorflow:From C:\\Users\\masao\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "accuracy: 0.796239\n",
      "precision: 0.737244\n",
      "recall: 0.710087\n",
      "AUROC: 0.868899\n",
      "day to night =========================================\n",
      "accuracy: 0.764079\n",
      "precision: 0.820472\n",
      "recall: 0.859563\n",
      "AUROC: 0.737120\n",
      "night out =========================================\n",
      "accuracy: 0.712258\n",
      "precision: 0.620940\n",
      "recall: 0.596413\n",
      "AUROC: 0.745895\n",
      "vacation =========================================\n",
      "accuracy: 0.751951\n",
      "precision: 0.685487\n",
      "recall: 0.623311\n",
      "AUROC: 0.788861\n",
      "weekend =========================================\n",
      "accuracy: 0.771812\n",
      "precision: 0.837139\n",
      "recall: 0.872775\n",
      "AUROC: 0.726877\n",
      "work =========================================\n",
      "accuracy: 0.765839\n",
      "precision: 0.686095\n",
      "recall: 0.683000\n",
      "AUROC: 0.822514\n",
      "workout =========================================\n",
      "accuracy: 0.864175\n",
      "precision: 0.829932\n",
      "recall: 0.812000\n",
      "AUROC: 0.923065\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for occasion in occasionlist:\n",
    "    \n",
    "    print(occasion,'=========================================')\n",
    "    \n",
    "    acclist = []\n",
    "    precisionlist = []\n",
    "    recalllist = []\n",
    "    auclist = []\n",
    "\n",
    "    data = Occasion.groupby('tag_info').agg(specific_occasion = pd.NamedAgg(column=occasion, aggfunc='max')).reset_index()\n",
    "    \n",
    "    # 'day to night' and 'weekend' labels are pretty balanced\n",
    "    \n",
    "    if occasion not in ['day to night', 'weekend']:\n",
    "        data1 = data[data['specific_occasion']==1]\n",
    "        data2 = data[data['specific_occasion']==0].sample(round(len(data1)*1.7), random_state=123)\n",
    "    else:\n",
    "        data1 = data[data['specific_occasion']==1]\n",
    "        data2 = data[data['specific_occasion']==0]\n",
    "        \n",
    "    data = pd.concat([data1, data2])\n",
    "    tag_list = list(data['tag_info'])\n",
    "\n",
    "    # Tokenize the Text\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(tag_list)\n",
    "\n",
    "    # get the max length in terms of token length\n",
    "    max_length = get_max_token_length_per_doc(tag_list)\n",
    "\n",
    "    # integer encode the documents\n",
    "    encoded_docs = integer_encode_documents(tag_list, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    labels = data['specific_occasion']\n",
    "    labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "    X_train = padded_docs\n",
    "    y_train = labels\n",
    "    \n",
    "    VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "    # Load in Embeddings\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    def make_lstm_classification_model(plot=False):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "        model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "        model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "        # model.add(Dense(16))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            plot_model(model, to_file='model.png', show_shapes=True)\n",
    "        return model\n",
    "    \n",
    "    for loop in range(3):\n",
    "        \n",
    "        model = make_lstm_classification_model()\n",
    "        \n",
    "        # k-fold cross validation\n",
    "        kfold = KFold(n_splits=10, shuffle=True)\n",
    "        # enumerate splits\n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "            # split train & test\n",
    "            cross_train_X, cross_test_X = X_train[train_index], X_train[test_index]\n",
    "            cross_train_y, cross_test_y = y_train[train_index], y_train[test_index]\n",
    "            # fit model\n",
    "            model = make_lstm_classification_model()\n",
    "            model.fit(cross_train_X, cross_train_y, epochs=15, verbose=0)\n",
    "            # evaluate model\n",
    "            y_prob = model.predict(cross_test_X) \n",
    "            y_classes = y_prob.argmax(axis=-1)\n",
    "            ytest = [np.argmax(y, axis=None, out=None) for y in cross_test_y]\n",
    "            # acc\n",
    "            acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "            # precision \n",
    "            precision = sklearn.metrics.precision_score(ytest, y_classes)\n",
    "            # recall\n",
    "            recall = sklearn.metrics.recall_score(ytest, y_classes)\n",
    "            # auc\n",
    "            auc = sklearn.metrics.roc_auc_score(ytest, [y[1] for y in y_prob])\n",
    "\n",
    "            acclist.append(acc)\n",
    "            precisionlist.append(precision)\n",
    "            recalllist.append(recall)\n",
    "            auclist.append(auc)\n",
    "\n",
    "    print('accuracy: %f' % np.mean(acclist))\n",
    "    print('precision: %f' % np.mean(precisionlist))\n",
    "    print('recall: %f' % np.mean(recalllist))\n",
    "    print('AUROC: %f' % np.mean(auclist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '33'></a>\n",
    "\n",
    "## Performance 3: LSTM for all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_info</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a.l.c lennox high waist cotton linen pant unkn...</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana republic mock-neck sweater top unknown ...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simon miller rost belted short unknown true si...</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a.l.c minelli silk sleeveless top unknown true...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simon miller nepa mismatched button rib cardig...</td>\n",
       "      <td>sweater</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tag_info attribute_value\n",
       "0  a.l.c lennox high waist cotton linen pant unkn...          bottom\n",
       "1  banana republic mock-neck sweater top unknown ...             top\n",
       "2  simon miller rost belted short unknown true si...          bottom\n",
       "3  a.l.c minelli silk sleeveless top unknown true...             top\n",
       "4  simon miller nepa mismatched button rib cardig...         sweater"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Category = join_data[join_data[\"attribute_name\"] == 'category'][['tag_info', 'attribute_value']].drop_duplicates().reset_index(drop=True)\n",
    "Category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>quantifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Top</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Shoe</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Handbag</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Scarf</td>\n",
       "      <td>category</td>\n",
       "      <td>general</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value  category     type quantifier\n",
       "64        Top  category  general        one\n",
       "65     Bottom  category  general        one\n",
       "66  One Piece  category  general        one\n",
       "67       Shoe  category  general        one\n",
       "68    Handbag  category  general        one\n",
       "69      Scarf  category  general        one"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data dictionary shows there are six categories in total\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select *  from categories\")\n",
    "data = cur.fetchall()\n",
    "category = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])\n",
    "category[category[\"category\"] == \"category\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessory',\n",
       " 'blazers, coats & jackets',\n",
       " 'blazerscoatsjackets',\n",
       " 'bottom',\n",
       " 'one piece',\n",
       " 'onepiece',\n",
       " 'shoe',\n",
       " 'sweater',\n",
       " 'sweatshirt & hoodie',\n",
       " 'sweatshirthoodie',\n",
       " 'top'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but actually there are 11 tags \n",
    "set(Category.attribute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessory',\n",
       " 'blazers, coats & jackets',\n",
       " 'bottom',\n",
       " 'one piece',\n",
       " 'shoe',\n",
       " 'sweater',\n",
       " 'sweatshirt & hoodie',\n",
       " 'top'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we merged three categories with their synonym and turn 11 categories into 8\n",
    "Category.loc[Category['attribute_value'] == 'blazerscoatsjackets', 'attribute_value'] =  'blazers, coats & jackets'\n",
    "Category.loc[Category['attribute_value'] == 'onepiece', 'attribute_value'] = 'one piece'\n",
    "Category.loc[Category['attribute_value'] == 'sweatshirthoodie', 'attribute_value'] =  'sweatshirt & hoodie'\n",
    "set(Category.attribute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_info</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute_value</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accessory</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blazers, coats &amp; jackets</th>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottom</th>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one piece</th>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoe</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweater</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweatshirt &amp; hoodie</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tag_info\n",
       "attribute_value                   \n",
       "accessory                      327\n",
       "blazers, coats & jackets       385\n",
       "bottom                         943\n",
       "one piece                      581\n",
       "shoe                           695\n",
       "sweater                        302\n",
       "sweatshirt & hoodie            141\n",
       "top                            975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# their distribution is as follows:\n",
    "Category.groupby('attribute_value').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same LSTM model, the only difference is multiple classification at the output layer \n",
    "stopwords_removed_docs = list(Category['tag_info'])\n",
    "max_length = get_max_token_length_per_doc(stopwords_removed_docs)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(stopwords_removed_docs)\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "# Notice the last document has 4 numbers, since it is a 4 word document: Could have done better.\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = Category.attribute_value\n",
    "labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.1, random_state=23)\n",
    "\n",
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 187, 100)          1035300   \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 187, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 1,052,988\n",
      "Trainable params: 17,688\n",
      "Non-trainable params: 1,035,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model = make_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/20\n",
      "3522/3522 [==============================] - 16s 5ms/step - loss: 1.6841 - accuracy: 0.3927 - val_loss: 1.1568 - val_accuracy: 0.5893\n",
      "Epoch 2/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 1.0059 - accuracy: 0.6505 - val_loss: 0.7795 - val_accuracy: 0.7296\n",
      "Epoch 3/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.6985 - accuracy: 0.7521 - val_loss: 0.5809 - val_accuracy: 0.7985\n",
      "Epoch 4/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.5071 - accuracy: 0.8271 - val_loss: 0.4016 - val_accuracy: 0.8546\n",
      "Epoch 5/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.3762 - accuracy: 0.8768 - val_loss: 0.3216 - val_accuracy: 0.8929\n",
      "Epoch 6/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.2645 - accuracy: 0.9242 - val_loss: 0.3376 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.6246 - accuracy: 0.8103 - val_loss: 0.3519 - val_accuracy: 0.9031\n",
      "Epoch 8/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.2679 - accuracy: 0.9256 - val_loss: 0.2465 - val_accuracy: 0.9337\n",
      "Epoch 9/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.1905 - accuracy: 0.9492 - val_loss: 0.2057 - val_accuracy: 0.9464\n",
      "Epoch 10/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.1724 - accuracy: 0.9543 - val_loss: 0.1970 - val_accuracy: 0.9439\n",
      "Epoch 11/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.1342 - accuracy: 0.9688 - val_loss: 0.1610 - val_accuracy: 0.9515\n",
      "Epoch 12/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.1100 - accuracy: 0.9744 - val_loss: 0.1535 - val_accuracy: 0.9617\n",
      "Epoch 13/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.1001 - accuracy: 0.9759 - val_loss: 0.1561 - val_accuracy: 0.9541\n",
      "Epoch 14/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.0892 - accuracy: 0.9796 - val_loss: 0.1461 - val_accuracy: 0.9592\n",
      "Epoch 15/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.0779 - accuracy: 0.9815 - val_loss: 0.1513 - val_accuracy: 0.9617\n",
      "Epoch 16/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.0688 - accuracy: 0.9844 - val_loss: 0.1427 - val_accuracy: 0.9668\n",
      "Epoch 17/20\n",
      "3522/3522 [==============================] - 14s 4ms/step - loss: 0.0617 - accuracy: 0.9867 - val_loss: 0.1606 - val_accuracy: 0.9643\n",
      "Epoch 18/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.0591 - accuracy: 0.9864 - val_loss: 0.1355 - val_accuracy: 0.9668\n",
      "Epoch 19/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.0520 - accuracy: 0.9884 - val_loss: 0.1381 - val_accuracy: 0.9694\n",
      "Epoch 20/20\n",
      "3522/3522 [==============================] - 13s 4ms/step - loss: 0.0535 - accuracy: 0.9864 - val_loss: 0.1488 - val_accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(X_train, y_train,validation_split = 0.1, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_fit_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_fit_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435/435 [==============================] - 0s 1ms/step\n",
      "Test Accuracy: 96.091956\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.960920\n",
      "AUROC: 0.994840\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "y_prob = model.predict(X_test) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "ytest = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "# acc\n",
    "acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "# auc\n",
    "auc = sklearn.metrics.roc_auc_score(ytest, y_prob, multi_class='ovo')\n",
    "\n",
    "print('accuracy: %f' % acc)\n",
    "print('AUROC: %f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '4'></a>\n",
    "\n",
    "# IV. Prediction: get tags for full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is designed for prediction. There're 2 ways you can use this tool: \n",
    "- 1. We've provided a prediction data template (prediction_data_template.xlsx) for you to plug in all the texts you need to change. After doing so, you could use the following 2 lines to load the data in. And then all that's left to do is to run through all the cells in this part.\n",
    "```\n",
    "import pandas as pd\n",
    "full_data = pd.read_excel('prediction_data_template.xlsx')\n",
    "```\n",
    "\n",
    "- 2. You can make your own data set with new features as well. For example, you can design your columns as `brand`,`brand_type`,`details`,`descriptions`,`new_details`. In this case, please make sure to name your dataframe as `full_data` after loading it in. Also, if you use your own prediction dataset, please comment out the 3rd line in the next kernel and run the 4th line instead.\n",
    "\n",
    "Before you run this part, please make sure you've already run part I Load Data and II Text Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.replace(np.nan, \"\", regex=True)\n",
    "full_data = full_data.replace(\"\\n\", \"\",regex=True)\n",
    "full_data['tag_info'] = full_data[['brand','product_full_name','brand_category','details','description']].apply(lambda x: ' '.join(x), axis=1)\n",
    "#full_data['tag_info'] = full_data[list(full_data.columns)].apply(lambda x: ' '.join(x), axis=1)\n",
    "full_data['tag_info'] = full_data['tag_info'].str.lower()\n",
    "\n",
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "nltk_stopwords = set(stopwords.words('english') + [\".\",\",\",\":\",\"''\",\"'s\",\"'\",\"``\",\"(\", \")\",\"]\",\n",
    "                                                   \"-\",\"!\",\"/\",\">\",\"<\",\";\",\"#\",\"...\",\"..\",\"?\",\"--\",\"[\",\"&\"])\n",
    "full_data['tag_info'] = full_data['tag_info'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in nltk_stopwords]))\n",
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "full_data['tag_info'] = full_data['tag_info'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Import tools for tokenizaton and encoding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from typing import List\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Import Keras Toolkit\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import  LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "\n",
    "# Define integer encoder for documents\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "# Define max length detection tool\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# Load in GloVe Vectors\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_glove_vectors()\n",
    "\n",
    "# import K-Fold validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform full_data['tag_info'] to keras input format\n",
    "full_input = list(full_data['tag_info'])\n",
    "tokenizer = Tokenizer(num_words=4000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(full_input)\n",
    "# Decide the max length of padding size\n",
    "# Be super careful the padding size of model must be larger (at least equal to) max_length of both training and testing (prediction) set\n",
    "max_length = get_max_token_length_per_doc(full_input)\n",
    "full_encoded_docs = integer_encode_documents(full_input, tokenizer)\n",
    "full_padded_docs = pad_sequences(full_encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_input2 only take 1500 most frequent words but not 4000, because some of the styles/occasion has too few samples\n",
    "# Actually only one model use 1500 most frequent words - workout in Ocaasion, which only has around 150 samples, \n",
    "# but the performance is still good\n",
    "full_input2 = list(full_data['tag_info'])\n",
    "tokenizer2 = Tokenizer(num_words=1500, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer2.fit_on_texts(full_input2)\n",
    "full_encoded_docs2 = integer_encode_documents(full_input2, tokenizer)\n",
    "full_padded_docs2 = pad_sequences(full_encoded_docs2, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a view of max_length\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's training set\n",
    "join_data['tag_info'] = join_data[['brand','product_full_name','brand_category','details','description']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '41'></a>\n",
    "\n",
    "## Prediction 1: Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When training model for prediction, should do some format preprocessing to training data set. Here we set the join_data from \n",
    "# Part1 & 2 (postgresql database) as our default training dat\n",
    "Style = join_data[join_data['attribute_name']=='style'][['tag_info', 'attribute_value']].drop_duplicates()\n",
    "Style.loc[Style['attribute_value'] =='businesscasual', 'attribute_value'] = 'business casual'\n",
    "stylelist = list(np.unique(Style['attribute_value']))\n",
    "Style.reset_index(drop=True, inplace=True)\n",
    "# Prepare data\n",
    "for sty in np.unique(Style['attribute_value']):\n",
    "    Style[sty] = 0\n",
    "    Style[sty][Style['attribute_value']==sty]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "androgynous =========================================\n",
      "Epoch 1/15\n",
      "1993/1993 [==============================] - 13s 6ms/step - loss: 0.6508 - accuracy: 0.6267 3s\n",
      "Epoch 2/15\n",
      "1993/1993 [==============================] - 12s 6ms/step - loss: 0.6000 - accuracy: 0.6739 \n",
      "Epoch 3/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.5385 - accuracy: 0.7371\n",
      "Epoch 4/15\n",
      "1993/1993 [==============================] - 11s 5ms/step - loss: 0.5074 - accuracy: 0.7561 2s - l\n",
      "Epoch 5/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.4884 - accuracy: 0.7702\n",
      "Epoch 6/15\n",
      "1993/1993 [==============================] - 13s 6ms/step - loss: 0.4506 - accuracy: 0.7827\n",
      "Epoch 7/15\n",
      "1993/1993 [==============================] - 11s 5ms/step - loss: 0.4322 - accuracy: 0.7973\n",
      "Epoch 8/15\n",
      "1993/1993 [==============================] - 11s 5ms/step - loss: 0.3977 - accuracy: 0.8144\n",
      "Epoch 9/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.3674 - accuracy: 0.8364\n",
      "Epoch 10/15\n",
      "1993/1993 [==============================] - 11s 5ms/step - loss: 0.3641 - accuracy: 0.8379\n",
      "Epoch 11/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.3187 - accuracy: 0.8595\n",
      "Epoch 12/15\n",
      "1993/1993 [==============================] - 10s 5ms/step - loss: 0.2789 - accuracy: 0.8826\n",
      "Epoch 13/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.2705 - accuracy: 0.8856\n",
      "Epoch 14/15\n",
      "1993/1993 [==============================] - 11s 5ms/step - loss: 0.2284 - accuracy: 0.9047\n",
      "Epoch 15/15\n",
      "1993/1993 [==============================] - 11s 6ms/step - loss: 0.2039 - accuracy: 0.9192\n",
      "training accuracy: 0.933768\n",
      "training AUROC: 0.959991\n",
      "athleisure =========================================\n",
      "Epoch 1/15\n",
      "761/761 [==============================] - 5s 7ms/step - loss: 0.6577 - accuracy: 0.6110\n",
      "Epoch 2/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.6109 - accuracy: 0.6636\n",
      "Epoch 3/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.4779 - accuracy: 0.7871\n",
      "Epoch 4/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.3671 - accuracy: 0.8699\n",
      "Epoch 5/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.4129 - accuracy: 0.8331\n",
      "Epoch 6/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.3322 - accuracy: 0.8817\n",
      "Epoch 7/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.2815 - accuracy: 0.9028\n",
      "Epoch 8/15\n",
      "761/761 [==============================] - 5s 6ms/step - loss: 0.2606 - accuracy: 0.9080\n",
      "Epoch 9/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.2437 - accuracy: 0.9133: 1s - loss: 0.2305 - accura - ETA: 0s - loss: 0.2400 - accuracy\n",
      "Epoch 10/15\n",
      "761/761 [==============================] - 4s 5ms/step - loss: 0.2580 - accuracy: 0.9054\n",
      "Epoch 11/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.2153 - accuracy: 0.9290: 1s - loss: 0.2081 - \n",
      "Epoch 12/15\n",
      "761/761 [==============================] - 4s 6ms/step - loss: 0.2365 - accuracy: 0.9146\n",
      "Epoch 13/15\n",
      "761/761 [==============================] - 4s 5ms/step - loss: 0.2089 - accuracy: 0.9277: 3s\n",
      "Epoch 14/15\n",
      "761/761 [==============================] - 4s 5ms/step - loss: 0.1971 - accuracy: 0.9304\n",
      "Epoch 15/15\n",
      "761/761 [==============================] - 4s 5ms/step - loss: 0.1610 - accuracy: 0.9461\n",
      "training accuracy: 0.955322\n",
      "training AUROC: 0.981041\n",
      "boho =========================================\n",
      "Epoch 1/15\n",
      "1337/1337 [==============================] - 9s 7ms/step - loss: 0.6495 - accuracy: 0.6253\n",
      "Epoch 2/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.5935 - accuracy: 0.6776\n",
      "Epoch 3/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.5414 - accuracy: 0.7367\n",
      "Epoch 4/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.5326 - accuracy: 0.7435\n",
      "Epoch 5/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.5031 - accuracy: 0.7674\n",
      "Epoch 6/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.4655 - accuracy: 0.7749\n",
      "Epoch 7/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.4414 - accuracy: 0.7973\n",
      "Epoch 8/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.4070 - accuracy: 0.8212\n",
      "Epoch 9/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.3702 - accuracy: 0.8377\n",
      "Epoch 10/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.3450 - accuracy: 0.8504\n",
      "Epoch 11/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.3142 - accuracy: 0.8616\n",
      "Epoch 12/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.2712 - accuracy: 0.8841\n",
      "Epoch 13/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.2365 - accuracy: 0.9132\n",
      "Epoch 14/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.2459 - accuracy: 0.9050\n",
      "Epoch 15/15\n",
      "1337/1337 [==============================] - 8s 6ms/step - loss: 0.2235 - accuracy: 0.9065: 0s - loss: 0.2239 - accuracy: 0.\n",
      "training accuracy: 0.943156\n",
      "training AUROC: 0.982406\n",
      "business casual =========================================\n",
      "Epoch 1/15\n",
      "3164/3164 [==============================] - 20s 6ms/step - loss: 0.6496 - accuracy: 0.6343\n",
      "Epoch 2/15\n",
      "3164/3164 [==============================] - 19s 6ms/step - loss: 0.5916 - accuracy: 0.6700\n",
      "Epoch 3/15\n",
      "3164/3164 [==============================] - 19s 6ms/step - loss: 0.5439 - accuracy: 0.7086\n",
      "Epoch 4/15\n",
      "3164/3164 [==============================] - 19s 6ms/step - loss: 0.5040 - accuracy: 0.7503\n",
      "Epoch 5/15\n",
      "3164/3164 [==============================] - 19s 6ms/step - loss: 0.4666 - accuracy: 0.7728\n",
      "Epoch 6/15\n",
      "3164/3164 [==============================] - 19s 6ms/step - loss: 0.4414 - accuracy: 0.7911\n",
      "Epoch 7/15\n",
      "3164/3164 [==============================] - 18s 6ms/step - loss: 0.4296 - accuracy: 0.8015\n",
      "Epoch 8/15\n",
      "3164/3164 [==============================] - 18s 6ms/step - loss: 0.3908 - accuracy: 0.8240\n",
      "Epoch 9/15\n",
      "3164/3164 [==============================] - 18s 6ms/step - loss: 0.3605 - accuracy: 0.8353\n",
      "Epoch 10/15\n",
      "3164/3164 [==============================] - 18s 6ms/step - loss: 0.3341 - accuracy: 0.8521\n",
      "Epoch 11/15\n",
      "3164/3164 [==============================] - 17s 6ms/step - loss: 0.3206 - accuracy: 0.8597\n",
      "Epoch 12/15\n",
      "3164/3164 [==============================] - 17s 5ms/step - loss: 0.2795 - accuracy: 0.8818\n",
      "Epoch 13/15\n",
      "3164/3164 [==============================] - 17s 5ms/step - loss: 0.2700 - accuracy: 0.8815\n",
      "Epoch 14/15\n",
      "3164/3164 [==============================] - 17s 5ms/step - loss: 0.2455 - accuracy: 0.8979\n",
      "Epoch 15/15\n",
      "3164/3164 [==============================] - 18s 6ms/step - loss: 0.2090 - accuracy: 0.9166\n",
      "training accuracy: 0.941846\n",
      "training AUROC: 0.975947\n",
      "casual =========================================\n",
      "Epoch 1/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.6077 - accuracy: 0.6714\n",
      "Epoch 2/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.4920 - accuracy: 0.7552\n",
      "Epoch 3/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.4483 - accuracy: 0.7838\n",
      "Epoch 4/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.4151 - accuracy: 0.8065 0s - loss: 0.4140 - accuracy: 0.80\n",
      "Epoch 5/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3934 - accuracy: 0.8142\n",
      "Epoch 6/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3724 - accuracy: 0.8321\n",
      "Epoch 7/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3376 - accuracy: 0.8448\n",
      "Epoch 8/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3239 - accuracy: 0.8555\n",
      "Epoch 9/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2930 - accuracy: 0.8699\n",
      "Epoch 10/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2680 - accuracy: 0.8823\n",
      "Epoch 11/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2506 - accuracy: 0.8950\n",
      "Epoch 12/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2269 - accuracy: 0.9092\n",
      "Epoch 13/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2011 - accuracy: 0.9189\n",
      "Epoch 14/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.1747 - accuracy: 0.9281\n",
      "Epoch 15/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.1557 - accuracy: 0.9398\n",
      "training accuracy: 0.942537\n",
      "training AUROC: 0.977912\n",
      "classic =========================================\n",
      "Epoch 1/15\n",
      "4020/4020 [==============================] - 25s 6ms/step - loss: 0.6534 - accuracy: 0.6055\n",
      "Epoch 2/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.6189 - accuracy: 0.6532\n",
      "Epoch 3/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.5831 - accuracy: 0.6836 1s - loss: 0.5824 - \n",
      "Epoch 4/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.5532 - accuracy: 0.7090\n",
      "Epoch 5/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.5157 - accuracy: 0.7371 0s - loss: 0.5162 - accura\n",
      "Epoch 6/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.4830 - accuracy: 0.7719\n",
      "Epoch 7/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.4568 - accuracy: 0.7871 0s - loss: 0.4575 - accuracy: \n",
      "Epoch 8/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.4255 - accuracy: 0.8035\n",
      "Epoch 9/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.3901 - accuracy: 0.8254\n",
      "Epoch 10/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.3617 - accuracy: 0.8440\n",
      "Epoch 11/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3559 - accuracy: 0.8408\n",
      "Epoch 12/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.3032 - accuracy: 0.8699 0s - loss: 0.3049 - accura\n",
      "Epoch 13/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2904 - accuracy: 0.8771\n",
      "Epoch 14/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2489 - accuracy: 0.8985\n",
      "Epoch 15/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.2140 - accuracy: 0.9197\n",
      "training accuracy: 0.939055\n",
      "training AUROC: 0.974529\n",
      "edgy =========================================\n",
      "Epoch 1/15\n",
      "2217/2217 [==============================] - 14s 6ms/step - loss: 0.6450 - accuracy: 0.6184\n",
      "Epoch 2/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.6087 - accuracy: 0.6730\n",
      "Epoch 3/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.5766 - accuracy: 0.6942\n",
      "Epoch 4/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.5314 - accuracy: 0.7285\n",
      "Epoch 5/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.4914 - accuracy: 0.7614\n",
      "Epoch 6/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.4654 - accuracy: 0.7776\n",
      "Epoch 7/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.4281 - accuracy: 0.8042\n",
      "Epoch 8/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.3920 - accuracy: 0.8254\n",
      "Epoch 9/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.3571 - accuracy: 0.8457\n",
      "Epoch 10/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.3218 - accuracy: 0.8629\n",
      "Epoch 11/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.2919 - accuracy: 0.8814\n",
      "Epoch 12/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.2886 - accuracy: 0.8764\n",
      "Epoch 13/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.2286 - accuracy: 0.9053\n",
      "Epoch 14/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.2153 - accuracy: 0.9193\n",
      "Epoch 15/15\n",
      "2217/2217 [==============================] - 13s 6ms/step - loss: 0.1809 - accuracy: 0.9373 2s - los\n",
      "training accuracy: 0.944520\n",
      "training AUROC: 0.978165\n",
      "glam =========================================\n",
      "Epoch 1/15\n",
      "1212/1212 [==============================] - 8s 7ms/step - loss: 0.6495 - accuracy: 0.6229\n",
      "Epoch 2/15\n",
      "1212/1212 [==============================] - 8s 7ms/step - loss: 0.5928 - accuracy: 0.6724\n",
      "Epoch 3/15\n",
      "1212/1212 [==============================] - 8s 7ms/step - loss: 0.5245 - accuracy: 0.7170\n",
      "Epoch 4/15\n",
      "1212/1212 [==============================] - 8s 6ms/step - loss: 0.4772 - accuracy: 0.7558\n",
      "Epoch 5/15\n",
      "1212/1212 [==============================] - 8s 6ms/step - loss: 0.4422 - accuracy: 0.7781\n",
      "Epoch 6/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.4120 - accuracy: 0.7954\n",
      "Epoch 7/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.4192 - accuracy: 0.7929\n",
      "Epoch 8/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.3666 - accuracy: 0.8383\n",
      "Epoch 9/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.3526 - accuracy: 0.8432\n",
      "Epoch 10/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.3270 - accuracy: 0.8515\n",
      "Epoch 11/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.2869 - accuracy: 0.8738\n",
      "Epoch 12/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.2804 - accuracy: 0.8837\n",
      "Epoch 13/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.2576 - accuracy: 0.8927: 2s - loss:\n",
      "Epoch 14/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.2241 - accuracy: 0.9092\n",
      "Epoch 15/15\n",
      "1212/1212 [==============================] - 7s 6ms/step - loss: 0.2123 - accuracy: 0.9200\n",
      "training accuracy: 0.928218\n",
      "training AUROC: 0.981986\n",
      "modern =========================================\n",
      "Epoch 1/15\n",
      "4020/4020 [==============================] - 25s 6ms/step - loss: 0.6404 - accuracy: 0.6348\n",
      "Epoch 2/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.5727 - accuracy: 0.6993\n",
      "Epoch 3/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.5413 - accuracy: 0.7204\n",
      "Epoch 4/15\n",
      "4020/4020 [==============================] - 24s 6ms/step - loss: 0.5227 - accuracy: 0.7423\n",
      "Epoch 5/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.5020 - accuracy: 0.7532\n",
      "Epoch 6/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.4796 - accuracy: 0.7719\n",
      "Epoch 7/15\n",
      "4020/4020 [==============================] - 22s 5ms/step - loss: 0.4538 - accuracy: 0.7853\n",
      "Epoch 8/15\n",
      "4020/4020 [==============================] - 23s 6ms/step - loss: 0.4335 - accuracy: 0.7993\n",
      "Epoch 9/15\n",
      "4020/4020 [==============================] - 22s 5ms/step - loss: 0.4057 - accuracy: 0.8152 1s - loss: 0.4053 - \n",
      "Epoch 10/15\n",
      "4020/4020 [==============================] - 22s 5ms/step - loss: 0.3708 - accuracy: 0.8326\n",
      "Epoch 11/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.3456 - accuracy: 0.8473 0s - loss: 0.3402 - accura - ETA: 0s - loss: 0.3454 - accuracy: 0.84\n",
      "Epoch 12/15\n",
      "4020/4020 [==============================] - 22s 5ms/step - loss: 0.3168 - accuracy: 0.8714\n",
      "Epoch 13/15\n",
      "4020/4020 [==============================] - 22s 5ms/step - loss: 0.2732 - accuracy: 0.8883\n",
      "Epoch 14/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.2407 - accuracy: 0.9075 1s - loss: 0.2\n",
      "Epoch 15/15\n",
      "4020/4020 [==============================] - 22s 6ms/step - loss: 0.2230 - accuracy: 0.9124\n",
      "training accuracy: 0.930846\n",
      "training AUROC: 0.977930\n",
      "retro =========================================\n",
      "Epoch 1/15\n",
      "640/640 [==============================] - 4s 7ms/step - loss: 0.6629 - accuracy: 0.6297\n",
      "Epoch 2/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.6415 - accuracy: 0.6344: 1s - loss: 0.6559 \n",
      "Epoch 3/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.6222 - accuracy: 0.6453\n",
      "Epoch 4/15\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.6047 - accuracy: 0.6766\n",
      "Epoch 5/15\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.5653 - accuracy: 0.7312\n",
      "Epoch 6/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.5327 - accuracy: 0.7453\n",
      "Epoch 7/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.4934 - accuracy: 0.7703\n",
      "Epoch 8/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.4498 - accuracy: 0.7984: 1s - loss: 0.4544 - \n",
      "Epoch 9/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.3949 - accuracy: 0.8359\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 4s 6ms/step - loss: 0.3322 - accuracy: 0.8703\n",
      "Epoch 11/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2856 - accuracy: 0.8969: 2s - los\n",
      "Epoch 12/15\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2320 - accuracy: 0.9297\n",
      "Epoch 13/15\n",
      "640/640 [==============================] - 4s 5ms/step - loss: 0.1852 - accuracy: 0.9422\n",
      "Epoch 14/15\n",
      "640/640 [==============================] - 3s 5ms/step - loss: 0.1573 - accuracy: 0.9484\n",
      "Epoch 15/15\n",
      "640/640 [==============================] - 3s 5ms/step - loss: 0.1472 - accuracy: 0.9594\n",
      "training accuracy: 0.975000\n",
      "training AUROC: 0.988556\n",
      "romantic =========================================\n",
      "Epoch 1/15\n",
      "1561/1561 [==============================] - 11s 7ms/step - loss: 0.6503 - accuracy: 0.6316\n",
      "Epoch 2/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.5891 - accuracy: 0.6823\n",
      "Epoch 3/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.5433 - accuracy: 0.7252\n",
      "Epoch 4/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.5187 - accuracy: 0.7380: 1s - loss: 0.5150 \n",
      "Epoch 5/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.4814 - accuracy: 0.7630\n",
      "Epoch 6/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.4498 - accuracy: 0.7886\n",
      "Epoch 7/15\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.80 - 9s 6ms/step - loss: 0.4255 - accuracy: 0.8053\n",
      "Epoch 8/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.4081 - accuracy: 0.8181\n",
      "Epoch 9/15\n",
      "1561/1561 [==============================] - 9s 5ms/step - loss: 0.3772 - accuracy: 0.8302\n",
      "Epoch 10/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.3852 - accuracy: 0.8193\n",
      "Epoch 11/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.3214 - accuracy: 0.8565: 0s - loss: 0.3213 - accuracy: 0.\n",
      "Epoch 12/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.2938 - accuracy: 0.8712\n",
      "Epoch 13/15\n",
      "1561/1561 [==============================] - 8s 5ms/step - loss: 0.2782 - accuracy: 0.8821\n",
      "Epoch 14/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.2396 - accuracy: 0.8981\n",
      "Epoch 15/15\n",
      "1561/1561 [==============================] - 9s 6ms/step - loss: 0.2299 - accuracy: 0.8988\n",
      "training accuracy: 0.921204\n",
      "training AUROC: 0.947150\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Style column\n",
    "full_data['Style'] = '0'\n",
    "for style in stylelist:\n",
    "    \n",
    "    print(style,'=========================================')\n",
    "\n",
    "    data = Style.groupby('tag_info').agg(specific_style = pd.NamedAgg(column=style, aggfunc='max')).reset_index()\n",
    "    data1 = data[data['specific_style']==1]\n",
    "    if round(len(data1)*1.7) <= len(data[data['specific_style']==0]):\n",
    "        data2 = data[data['specific_style']==0].sample(round(len(data1)*1.7), random_state=123)\n",
    "        data = pd.concat([data1, data2])\n",
    "        \n",
    "    tag_list = list(data['tag_info'])\n",
    "\n",
    "    # Tokenize the Text\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(tag_list)\n",
    "\n",
    "    # integer encode the documents\n",
    "    # maxlen here should be large enough to cover both training data and full_data (prediction set)\n",
    "    encoded_docs = integer_encode_documents(tag_list, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    labels = data['specific_style']\n",
    "    labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "    X_train = padded_docs\n",
    "    y_train = labels\n",
    "    \n",
    "    VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "    # Load in Embeddings\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    def make_lstm_classification_model(plot=False):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "        model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "        model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "        # model.add(Dense(16))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        if plot:\n",
    "            plot_model(model, to_file='model.png', show_shapes=True)\n",
    "        return model\n",
    "        \n",
    "    model = make_lstm_classification_model()\n",
    "    model.fit(X_train, y_train, epochs=15, verbose=1)\n",
    "    # evaluate model\n",
    "    y_prob = model.predict(X_train) \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    ytest = [np.argmax(y, axis=None, out=None) for y in y_train]\n",
    "    # acc\n",
    "    acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "    # auc\n",
    "    auc = sklearn.metrics.roc_auc_score(ytest, [y[1] for y in y_prob])\n",
    "\n",
    "    print('training accuracy: %f' % np.mean(acc))\n",
    "    print('training AUROC: %f' % np.mean(auc))\n",
    "    \n",
    "    y_prob_full = model.predict(full_padded_docs) \n",
    "    y_classes_full = y_prob_full.argmax(axis=-1)\n",
    "    full_data[style] = y_classes_full\n",
    "    full_data[style][full_data[style]==1] = style\n",
    "    full_data['Style'] = full_data[['Style', style]].apply(lambda x: ', '.join(x.astype('str')), axis = 1)\n",
    "    full_data.drop(style, axis=1, inplace=True)\n",
    "    \n",
    "full_data['Style'] = full_data['Style'].str.replace(r'0, |, 0', '')\n",
    "full_data['Style'] = full_data['Style'].str.replace(r'0', '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '42'></a>\n",
    "\n",
    "## Prediction 2: Occassion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When training model for prediction, should do some format preprocessing to training data set. Here we set the join_data from \n",
    "# Part1 & 2 (postgresql database) as our default training dat\n",
    "Occasion = join_data[join_data['attribute_name']=='occasion'][['tag_info', 'attribute_value']].drop_duplicates()\n",
    "Occasion.loc[Occasion['attribute_value'] ==   'daytonight', 'attribute_value'] =  'day to night'\n",
    "Occasion.loc[Occasion['attribute_value'] ==   'nightout', 'attribute_value'] =  'night out'\n",
    "occasionlist = list(np.unique(Occasion['attribute_value']))\n",
    "Occasion.reset_index(drop=True, inplace=True)\n",
    "# Prepare data\n",
    "for occ in np.unique(Occasion['attribute_value']):\n",
    "    Occasion[occ] = 0\n",
    "    Occasion[occ][Occasion['attribute_value']==occ]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coldweather =========================================\n",
      "Epoch 1/15\n",
      "653/653 [==============================] - 6s 9ms/step - loss: 0.6519 - accuracy: 0.6187\n",
      "Epoch 2/15\n",
      "653/653 [==============================] - 5s 7ms/step - loss: 0.5955 - accuracy: 0.7167\n",
      "Epoch 3/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.5116 - accuracy: 0.7565\n",
      "Epoch 4/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.4401 - accuracy: 0.7994\n",
      "Epoch 5/15\n",
      "653/653 [==============================] - 4s 7ms/step - loss: 0.4043 - accuracy: 0.8147\n",
      "Epoch 6/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.3688 - accuracy: 0.8438\n",
      "Epoch 7/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.3282 - accuracy: 0.8591\n",
      "Epoch 8/15\n",
      "653/653 [==============================] - 4s 7ms/step - loss: 0.3052 - accuracy: 0.8668\n",
      "Epoch 9/15\n",
      "653/653 [==============================] - 4s 7ms/step - loss: 0.2873 - accuracy: 0.8806\n",
      "Epoch 10/15\n",
      "653/653 [==============================] - 4s 7ms/step - loss: 0.2390 - accuracy: 0.9096\n",
      "Epoch 11/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.2126 - accuracy: 0.9081\n",
      "Epoch 12/15\n",
      "653/653 [==============================] - 4s 5ms/step - loss: 0.1996 - accuracy: 0.9188\n",
      "Epoch 13/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.1686 - accuracy: 0.9357\n",
      "Epoch 14/15\n",
      "653/653 [==============================] - 4s 6ms/step - loss: 0.1684 - accuracy: 0.9342\n",
      "Epoch 15/15\n",
      "653/653 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9510\n",
      "training accuracy: 0.967841\n",
      "training AUROC: 0.979842\n",
      "day to night =========================================\n",
      "Epoch 1/15\n",
      "4014/4014 [==============================] - 26s 7ms/step - loss: 0.5850 - accuracy: 0.7262\n",
      "Epoch 2/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.5494 - accuracy: 0.7469\n",
      "Epoch 3/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.5323 - accuracy: 0.7569\n",
      "Epoch 4/15\n",
      "4014/4014 [==============================] - 23s 6ms/step - loss: 0.5008 - accuracy: 0.7778\n",
      "Epoch 5/15\n",
      "4014/4014 [==============================] - 22s 5ms/step - loss: 0.4824 - accuracy: 0.7795 0s - loss: 0.4844 - accura\n",
      "Epoch 6/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.4514 - accuracy: 0.7980\n",
      "Epoch 7/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.4250 - accuracy: 0.8069\n",
      "Epoch 8/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.4029 - accuracy: 0.8206\n",
      "Epoch 9/15\n",
      "4014/4014 [==============================] - 23s 6ms/step - loss: 0.3765 - accuracy: 0.8346\n",
      "Epoch 10/15\n",
      "4014/4014 [==============================] - 23s 6ms/step - loss: 0.3505 - accuracy: 0.8515\n",
      "Epoch 11/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.3248 - accuracy: 0.8615\n",
      "Epoch 12/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.2999 - accuracy: 0.8722\n",
      "Epoch 13/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.2547 - accuracy: 0.8961\n",
      "Epoch 14/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.2420 - accuracy: 0.9038\n",
      "Epoch 15/15\n",
      "4014/4014 [==============================] - 22s 6ms/step - loss: 0.2076 - accuracy: 0.9173 2s - los\n",
      "training accuracy: 0.929497\n",
      "training AUROC: 0.922094\n",
      "night out =========================================\n",
      "Epoch 1/15\n",
      "2581/2581 [==============================] - 16s 6ms/step - loss: 0.6600 - accuracy: 0.6091\n",
      "Epoch 2/15\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.6323 - accuracy: 0.6362\n",
      "Epoch 3/15\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.6013 - accuracy: 0.6761\n",
      "Epoch 4/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.5540 - accuracy: 0.7303\n",
      "Epoch 5/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.5246 - accuracy: 0.7458\n",
      "Epoch 6/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.4939 - accuracy: 0.7524\n",
      "Epoch 7/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.4626 - accuracy: 0.7854\n",
      "Epoch 8/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.4279 - accuracy: 0.8047\n",
      "Epoch 9/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.4178 - accuracy: 0.8113\n",
      "Epoch 10/15\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.3621 - accuracy: 0.8392\n",
      "Epoch 11/15\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.3246 - accuracy: 0.8566\n",
      "Epoch 12/15\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.2829 - accuracy: 0.8849\n",
      "Epoch 13/15\n",
      "2581/2581 [==============================] - 14s 6ms/step - loss: 0.2537 - accuracy: 0.8946\n",
      "Epoch 14/15\n",
      "2581/2581 [==============================] - 14s 6ms/step - loss: 0.2325 - accuracy: 0.9004 1s - loss: 0.2241 - \n",
      "Epoch 15/15\n",
      "2581/2581 [==============================] - 14s 6ms/step - loss: 0.2203 - accuracy: 0.9047\n",
      "training accuracy: 0.931809\n",
      "training AUROC: 0.961601\n",
      "vacation =========================================\n",
      "Epoch 1/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.6488 - accuracy: 0.6376\n",
      "Epoch 2/15\n",
      "1849/1849 [==============================] - 10s 6ms/step - loss: 0.6071 - accuracy: 0.6712\n",
      "Epoch 3/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.5412 - accuracy: 0.7312\n",
      "Epoch 4/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.5098 - accuracy: 0.7474\n",
      "Epoch 5/15\n",
      "1849/1849 [==============================] - 9s 5ms/step - loss: 0.4766 - accuracy: 0.7696\n",
      "Epoch 6/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.4433 - accuracy: 0.7891\n",
      "Epoch 7/15\n",
      "1849/1849 [==============================] - 9s 5ms/step - loss: 0.4156 - accuracy: 0.8053\n",
      "Epoch 8/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.3995 - accuracy: 0.8177\n",
      "Epoch 9/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.3562 - accuracy: 0.8383\n",
      "Epoch 10/15\n",
      "1849/1849 [==============================] - 9s 5ms/step - loss: 0.3197 - accuracy: 0.8594\n",
      "Epoch 11/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.2914 - accuracy: 0.8729\n",
      "Epoch 12/15\n",
      "1849/1849 [==============================] - 9s 5ms/step - loss: 0.2777 - accuracy: 0.8810\n",
      "Epoch 13/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.2375 - accuracy: 0.9005\n",
      "Epoch 14/15\n",
      "1849/1849 [==============================] - 10s 5ms/step - loss: 0.2442 - accuracy: 0.8972\n",
      "Epoch 15/15\n",
      "1849/1849 [==============================] - 9s 5ms/step - loss: 0.1930 - accuracy: 0.9194\n",
      "training accuracy: 0.923202\n",
      "training AUROC: 0.981765\n",
      "weekend =========================================\n",
      "Epoch 1/15\n",
      "4014/4014 [==============================] - 22s 5ms/step - loss: 0.5430 - accuracy: 0.7666\n",
      "Epoch 2/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.5102 - accuracy: 0.7681\n",
      "Epoch 3/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.4762 - accuracy: 0.7780\n",
      "Epoch 4/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.4532 - accuracy: 0.7950\n",
      "Epoch 5/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.4239 - accuracy: 0.8127\n",
      "Epoch 6/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.4011 - accuracy: 0.8214\n",
      "Epoch 7/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.3729 - accuracy: 0.8388\n",
      "Epoch 8/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.3445 - accuracy: 0.8488\n",
      "Epoch 9/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.3187 - accuracy: 0.8595 0s - loss: 0.3168 - accuracy: 0.\n",
      "Epoch 10/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.2877 - accuracy: 0.8787\n",
      "Epoch 11/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.2626 - accuracy: 0.8946\n",
      "Epoch 12/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.2335 - accuracy: 0.9086\n",
      "Epoch 13/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.2119 - accuracy: 0.9138\n",
      "Epoch 14/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.1750 - accuracy: 0.9337\n",
      "Epoch 15/15\n",
      "4014/4014 [==============================] - 21s 5ms/step - loss: 0.1570 - accuracy: 0.9392\n",
      "training accuracy: 0.956153\n",
      "training AUROC: 0.974557\n",
      "work =========================================\n",
      "Epoch 1/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.6519 - accuracy: 0.6235\n",
      "Epoch 2/15\n",
      "3748/3748 [==============================] - 19s 5ms/step - loss: 0.6003 - accuracy: 0.6769\n",
      "Epoch 3/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.5516 - accuracy: 0.7166 0s - loss: 0.5518 - accuracy: 0.\n",
      "Epoch 4/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.5058 - accuracy: 0.7497\n",
      "Epoch 5/15\n",
      "3748/3748 [==============================] - 19s 5ms/step - loss: 0.4679 - accuracy: 0.7745\n",
      "Epoch 6/15\n",
      "3748/3748 [==============================] - 19s 5ms/step - loss: 0.4275 - accuracy: 0.7986\n",
      "Epoch 7/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.4091 - accuracy: 0.8151\n",
      "Epoch 8/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.3773 - accuracy: 0.8242\n",
      "Epoch 9/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.3493 - accuracy: 0.8477\n",
      "Epoch 10/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.3311 - accuracy: 0.8549\n",
      "Epoch 11/15\n",
      "3748/3748 [==============================] - 19s 5ms/step - loss: 0.3023 - accuracy: 0.8685\n",
      "Epoch 12/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.2752 - accuracy: 0.8802\n",
      "Epoch 13/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.2513 - accuracy: 0.8882\n",
      "Epoch 14/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.2307 - accuracy: 0.9055\n",
      "Epoch 15/15\n",
      "3748/3748 [==============================] - 20s 5ms/step - loss: 0.2016 - accuracy: 0.9210\n",
      "training accuracy: 0.937300\n",
      "training AUROC: 0.969308\n",
      "workout =========================================\n",
      "Epoch 1/15\n",
      "427/427 [==============================] - 3s 7ms/step - loss: 0.6276 - accuracy: 0.6440\n",
      "Epoch 2/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.5713 - accuracy: 0.6885\n",
      "Epoch 3/15\n",
      "427/427 [==============================] - 2s 6ms/step - loss: 0.4909 - accuracy: 0.7611: 0s - loss: 0.4944 - accuracy: 0.75\n",
      "Epoch 4/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.4349 - accuracy: 0.8033\n",
      "Epoch 5/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.3659 - accuracy: 0.8337\n",
      "Epoch 6/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.3040 - accuracy: 0.8712\n",
      "Epoch 7/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.2583 - accuracy: 0.8970\n",
      "Epoch 8/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.2075 - accuracy: 0.9204\n",
      "Epoch 9/15\n",
      "427/427 [==============================] - 2s 6ms/step - loss: 0.1812 - accuracy: 0.9274\n",
      "Epoch 10/15\n",
      "427/427 [==============================] - 2s 6ms/step - loss: 0.1752 - accuracy: 0.9297\n",
      "Epoch 11/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.1290 - accuracy: 0.9578\n",
      "Epoch 12/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.1150 - accuracy: 0.9649\n",
      "Epoch 13/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9742\n",
      "Epoch 14/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.0885 - accuracy: 0.9742\n",
      "Epoch 15/15\n",
      "427/427 [==============================] - 2s 5ms/step - loss: 0.0856 - accuracy: 0.9719\n",
      "training accuracy: 0.976581\n",
      "training AUROC: 0.996047\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Occasion column\n",
    "full_data['Occasion'] = '0'\n",
    "for occasion in occasionlist:\n",
    "    \n",
    "    print(occasion,'=========================================')\n",
    "\n",
    "    data = Occasion.groupby('tag_info').agg(specific_occasion = pd.NamedAgg(column=occasion, aggfunc='max')).reset_index()\n",
    "    \n",
    "    # 'day to night' and 'weekend' labels are pretty balanced\n",
    "    \n",
    "    if occasion not in ['day to night', 'weekend']:\n",
    "        data1 = data[data['specific_occasion']==1]\n",
    "        data2 = data[data['specific_occasion']==0].sample(round(len(data1)*1.7), random_state=123)\n",
    "    else:\n",
    "        data1 = data[data['specific_occasion']==1]\n",
    "        data2 = data[data['specific_occasion']==0]\n",
    "        \n",
    "    data = pd.concat([data1, data2])\n",
    "    tag_list = list(data['tag_info'])\n",
    "\n",
    "    # Tokenize the Text\n",
    "    \n",
    "    if occasion == 'workout':\n",
    "        tokenizer = Tokenizer(num_words=1500, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    else:\n",
    "        tokenizer = Tokenizer(num_words=4000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(tag_list)\n",
    "\n",
    "    # integer encode the documents\n",
    "    # maxlen here should be large enough to cover both training data and full_data (prediction set)\n",
    "    encoded_docs = integer_encode_documents(tag_list, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    labels = data['specific_occasion']\n",
    "    labels = to_categorical(encoder.fit_transform(labels))\n",
    "    \n",
    "    X_train = padded_docs\n",
    "    y_train = labels\n",
    "    \n",
    "    VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "    # Load in Embeddings\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    def make_lstm_classification_model(plot=False):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "        model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "        model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "        # model.add(Dense(16))\n",
    "        model.add(Dense(8))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        if plot:\n",
    "            plot_model(model, to_file='model.png', show_shapes=True)\n",
    "        return model\n",
    "        \n",
    "    model = make_lstm_classification_model()\n",
    "    model.fit(X_train, y_train, epochs=15, verbose=1)\n",
    "    # evaluate model\n",
    "    y_prob = model.predict(X_train) \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    ytest = [np.argmax(y, axis=None, out=None) for y in y_train]\n",
    "    # acc\n",
    "    acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "    # auc\n",
    "    auc = sklearn.metrics.roc_auc_score(ytest, [y[1] for y in y_prob])\n",
    "\n",
    "    print('training accuracy: %f' % np.mean(acc))\n",
    "    print('training AUROC: %f' % np.mean(auc))\n",
    "    \n",
    "    if occasion == 'workout':\n",
    "        y_prob_full = model.predict(full_padded_docs2) \n",
    "    else:\n",
    "        y_prob_full = model.predict(full_padded_docs) \n",
    "    y_classes_full = y_prob_full.argmax(axis=-1)\n",
    "    full_data[occasion] = y_classes_full\n",
    "    full_data[occasion][full_data[occasion]==1] = occasion\n",
    "    full_data['Occasion'] = full_data[['Occasion', occasion]].apply(lambda x: ', '.join(x.astype('str')), axis = 1)\n",
    "    full_data.drop(occasion, axis=1, inplace=True)\n",
    "    \n",
    "full_data['Occasion'] = full_data['Occasion'].str.replace(r'0, |, 0', '')\n",
    "full_data['Occasion'] = full_data['Occasion'].str.replace(r'0', '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '43'></a>\n",
    "\n",
    "## Prediction 3: Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When training model for prediction, should do some format preprocessing to training data set. Here we set the join_data from \n",
    "# Part1 & 2 (postgresql database) as our default training dat\n",
    "Category = join_data[join_data['attribute_name']=='category'][['tag_info', 'attribute_value']].drop_duplicates()\n",
    "Category.loc[Category['attribute_value'] ==   'blazerscoatsjackets', 'attribute_value'] =  'blazers, coats & jackets'\n",
    "Category.loc[Category['attribute_value'] ==   'onepiece', 'attribute_value'] = 'one piece'\n",
    "Category.loc[Category['attribute_value'] ==   'sweatshirthoodie', 'attribute_value'] =  'sweatshirt & hoodie'\n",
    "Category.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4103/4103 [==============================] - 30s 7ms/step - loss: 1.5514 - accuracy: 0.4346\n",
      "Epoch 2/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.8952 - accuracy: 0.6815\n",
      "Epoch 3/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.6136 - accuracy: 0.8036\n",
      "Epoch 4/20\n",
      "4103/4103 [==============================] - 26s 6ms/step - loss: 0.3882 - accuracy: 0.8801\n",
      "Epoch 5/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.3644 - accuracy: 0.8913\n",
      "Epoch 6/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.2149 - accuracy: 0.9427\n",
      "Epoch 7/20\n",
      "4103/4103 [==============================] - 26s 6ms/step - loss: 0.2056 - accuracy: 0.9420\n",
      "Epoch 8/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.1594 - accuracy: 0.9586\n",
      "Epoch 9/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.1254 - accuracy: 0.9683\n",
      "Epoch 10/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.0949 - accuracy: 0.9773\n",
      "Epoch 11/20\n",
      "4103/4103 [==============================] - 26s 6ms/step - loss: 0.1142 - accuracy: 0.9698\n",
      "Epoch 12/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.0799 - accuracy: 0.9795\n",
      "Epoch 13/20\n",
      "4103/4103 [==============================] - 26s 6ms/step - loss: 0.0650 - accuracy: 0.9842\n",
      "Epoch 14/20\n",
      "4103/4103 [==============================] - 25s 6ms/step - loss: 0.0573 - accuracy: 0.9861\n",
      "Epoch 15/20\n",
      "4103/4103 [==============================] - 24s 6ms/step - loss: 0.0507 - accuracy: 0.9876\n",
      "Epoch 16/20\n",
      "4103/4103 [==============================] - 24s 6ms/step - loss: 0.0566 - accuracy: 0.9856\n",
      "Epoch 17/20\n",
      "4103/4103 [==============================] - 24s 6ms/step - loss: 0.0619 - accuracy: 0.9832\n",
      "Epoch 18/20\n",
      "4103/4103 [==============================] - 23s 6ms/step - loss: 0.2256 - accuracy: 0.9357\n",
      "Epoch 19/20\n",
      "4103/4103 [==============================] - 23s 6ms/step - loss: 0.1277 - accuracy: 0.9659\n",
      "Epoch 20/20\n",
      "4103/4103 [==============================] - 23s 6ms/step - loss: 0.0635 - accuracy: 0.9844\n",
      "training accuracy: 0.990007\n",
      "training AUROC: 0.999309\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Category column\n",
    "\n",
    "data = Category.groupby('tag_info').agg(specific_category = pd.NamedAgg(column='attribute_value', aggfunc='first')).reset_index()\n",
    "tag_list = list(data['tag_info'])\n",
    "\n",
    "# Tokenize the Text\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(tag_list)\n",
    "\n",
    "# integer encode the documents\n",
    "# maxlen here should be large enough to cover both training data and full_data (prediction set)\n",
    "encoded_docs = integer_encode_documents(tag_list, tokenizer)\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = data['specific_category']\n",
    "labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "X_train = padded_docs\n",
    "y_train = labels\n",
    "\n",
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "\n",
    "# Load in Embeddings\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# define the model\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=32, input_shape=(1, max_length)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "model = make_lstm_classification_model()\n",
    "model.fit(X_train, y_train, epochs=20, verbose=1)\n",
    "\n",
    "# evaluate model\n",
    "y_prob = model.predict(X_train) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "ytest = [np.argmax(y, axis=None, out=None) for y in y_train]\n",
    "# acc\n",
    "acc = sklearn.metrics.accuracy_score(ytest, y_classes)\n",
    "# auc\n",
    "auc = sklearn.metrics.roc_auc_score(ytest, y_prob, multi_class='ovo')\n",
    "\n",
    "print('training accuracy: %f' % np.mean(acc))\n",
    "print('training AUROC: %f' % np.mean(auc))\n",
    "\n",
    "y_prob_full = model.predict(full_padded_docs) \n",
    "y_classes_full = y_prob_full.argmax(axis=-1)\n",
    "y_classes_full = encoder.inverse_transform(y_classes_full)\n",
    "\n",
    "full_data['Category'] = y_classes_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a view of final labelled full_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.drop('tag_info', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>Style</th>\n",
       "      <th>Occasion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>androgynous, athleisure, casual, classic, modern</td>\n",
       "      <td>day to night, work</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>androgynous, athleisure, boho, casual, modern,...</td>\n",
       "      <td>day to night, weekend, work</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protectionCase and cleaning cloth incl...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>casual, edgy, glam, modern, retro</td>\n",
       "      <td>weekend</td>\n",
       "      <td>sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upperRound toeLace-up vampSmartFOAM ins...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>androgynous, boho, business casual, casual, cl...</td>\n",
       "      <td>day to night, weekend, workout</td>\n",
       "      <td>one piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protectionGradient lensesAdjustable no...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>athleisure, boho, casual, classic, edgy, retro</td>\n",
       "      <td>day to night</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00       NULL   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protectionCase and cleaning cloth incl...  {\"Needs Review\"}   \n",
       "3  Canvas upperRound toeLace-up vampSmartFOAM ins...  {\"Needs Review\"}   \n",
       "4  100% UV protectionGradient lensesAdjustable no...  {\"Needs Review\"}   \n",
       "\n",
       "  bc_product_id                                              Style  \\\n",
       "0          NULL   androgynous, athleisure, casual, classic, modern   \n",
       "1          NULL  androgynous, athleisure, boho, casual, modern,...   \n",
       "2          NULL                  casual, edgy, glam, modern, retro   \n",
       "3          NULL  androgynous, boho, business casual, casual, cl...   \n",
       "4          NULL     athleisure, boho, casual, classic, edgy, retro   \n",
       "\n",
       "                         Occasion   Category  \n",
       "0              day to night, work        top  \n",
       "1     day to night, weekend, work     bottom  \n",
       "2                         weekend    sweater  \n",
       "3  day to night, weekend, workout  one piece  \n",
       "4                    day to night     bottom  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>Style</th>\n",
       "      <th>Occasion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48974</th>\n",
       "      <td>01DSNVXY8EJ9FQAJ3MPDMPASHD</td>\n",
       "      <td>Bonpoint</td>\n",
       "      <td>4.00091E+11</td>\n",
       "      <td>Baby's Hooded Jacket</td>\n",
       "      <td></td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Outerwear</td>\n",
       "      <td>2019-11-14 21:08:28.040417+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/bonpoint-babys...</td>\n",
       "      <td>Cozy double breasted jacket crafted from cotto...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>boho, casual, retro</td>\n",
       "      <td>day to night, vacation, weekend</td>\n",
       "      <td>blazers, coats &amp; jackets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48975</th>\n",
       "      <td>01DSGYHA3RMCHENBJVQPBGXM97</td>\n",
       "      <td>Laura Mercier</td>\n",
       "      <td>4.00096E+11</td>\n",
       "      <td>Flawless Fusion Ultra-Longwear Foundation</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>SaksBeautyPlace/ForHer/Color/Foundation/Liquid...</td>\n",
       "      <td>2019-11-12 23:17:47.761072+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/laura-mercier-...</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>androgynous, athleisure, casual, modern, romantic</td>\n",
       "      <td>day to night, night out, weekend</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48976</th>\n",
       "      <td>01DSJT8H12CAFQQH07SQSQWJ8C</td>\n",
       "      <td>Splendid</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>Baby Girl's 2-Piece Ruffle Sweatshirt &amp; Stripe...</td>\n",
       "      <td>Ruffled-trim sweatshirt lends romance to this ...</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Tops,JustKi...</td>\n",
       "      <td>2019-11-13 16:41:34.491443+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/splendid-baby-...</td>\n",
       "      <td>CrewneckLong sleevesRib-knit neck, cuffs and h...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>boho, classic, edgy, modern</td>\n",
       "      <td>day to night, weekend, work, workout</td>\n",
       "      <td>sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48977</th>\n",
       "      <td>01DSH2PF9J7QZ44D842B3GMCFN</td>\n",
       "      <td>Florence Eiseman</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Little Girl's Plaid &amp; Velvet Dress</td>\n",
       "      <td>Pretty plaid dress with velvet collar and velv...</td>\n",
       "      <td>JustKids/Girls214/ToddlerGirls24/Dresses,JustK...</td>\n",
       "      <td>2019-11-13 00:30:31.212215+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/florence-eisem...</td>\n",
       "      <td>Peter Pan collarShort sleevesBack zipperTwo fr...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>androgynous, boho, classic, modern, retro</td>\n",
       "      <td>day to night, weekend</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48978</th>\n",
       "      <td>01DSH54D3PWHKFZK5A8A2JE3RQ</td>\n",
       "      <td>Gucci</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>Baby Girl's Short-Sleeve Dress</td>\n",
       "      <td></td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Dresses</td>\n",
       "      <td>2019-11-13 01:13:04.880787+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NULL</td>\n",
       "      <td>https://www.saksfifthavenue.com/gucci-baby-gir...</td>\n",
       "      <td>Corduroy dress with bowCotton corduroyWeb gros...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NULL</td>\n",
       "      <td>modern</td>\n",
       "      <td>weekend</td>\n",
       "      <td>sweatshirt &amp; hoodie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_id             brand          mpn  \\\n",
       "48974  01DSNVXY8EJ9FQAJ3MPDMPASHD          Bonpoint  4.00091E+11   \n",
       "48975  01DSGYHA3RMCHENBJVQPBGXM97     Laura Mercier  4.00096E+11   \n",
       "48976  01DSJT8H12CAFQQH07SQSQWJ8C          Splendid    4.001E+11   \n",
       "48977  01DSH2PF9J7QZ44D842B3GMCFN  Florence Eiseman  4.00012E+11   \n",
       "48978  01DSH54D3PWHKFZK5A8A2JE3RQ             Gucci  4.00011E+11   \n",
       "\n",
       "                                       product_full_name  \\\n",
       "48974                               Baby's Hooded Jacket   \n",
       "48975          Flawless Fusion Ultra-Longwear Foundation   \n",
       "48976  Baby Girl's 2-Piece Ruffle Sweatshirt & Stripe...   \n",
       "48977                 Little Girl's Plaid & Velvet Dress   \n",
       "48978                     Baby Girl's Short-Sleeve Dress   \n",
       "\n",
       "                                             description  \\\n",
       "48974                                                      \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...   \n",
       "48976  Ruffled-trim sweatshirt lends romance to this ...   \n",
       "48977  Pretty plaid dress with velvet collar and velv...   \n",
       "48978                                                      \n",
       "\n",
       "                                          brand_category  \\\n",
       "48974       JustKids/Baby024months/InfantGirls/Outerwear   \n",
       "48975  SaksBeautyPlace/ForHer/Color/Foundation/Liquid...   \n",
       "48976  JustKids/Baby024months/InfantGirls/Tops,JustKi...   \n",
       "48977  JustKids/Girls214/ToddlerGirls24/Dresses,JustK...   \n",
       "48978         JustKids/Baby024months/InfantGirls/Dresses   \n",
       "\n",
       "                          created_at                     updated_at  \\\n",
       "48974  2019-11-14 21:08:28.040417+00  2019-12-19 20:40:30.786144+00   \n",
       "48975  2019-11-12 23:17:47.761072+00  2019-12-19 20:40:30.786144+00   \n",
       "48976  2019-11-13 16:41:34.491443+00  2019-12-19 20:40:30.786144+00   \n",
       "48977  2019-11-13 00:30:31.212215+00  2019-12-19 20:40:30.786144+00   \n",
       "48978  2019-11-13 01:13:04.880787+00  2019-12-19 20:40:30.786144+00   \n",
       "\n",
       "      deleted_at                                brand_canonical_url  \\\n",
       "48974       NULL  https://www.saksfifthavenue.com/bonpoint-babys...   \n",
       "48975       NULL  https://www.saksfifthavenue.com/laura-mercier-...   \n",
       "48976       NULL  https://www.saksfifthavenue.com/splendid-baby-...   \n",
       "48977       NULL  https://www.saksfifthavenue.com/florence-eisem...   \n",
       "48978       NULL  https://www.saksfifthavenue.com/gucci-baby-gir...   \n",
       "\n",
       "                                                 details            labels  \\\n",
       "48974  Cozy double breasted jacket crafted from cotto...  {\"Needs Review\"}   \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...  {\"Needs Review\"}   \n",
       "48976  CrewneckLong sleevesRib-knit neck, cuffs and h...  {\"Needs Review\"}   \n",
       "48977  Peter Pan collarShort sleevesBack zipperTwo fr...  {\"Needs Review\"}   \n",
       "48978  Corduroy dress with bowCotton corduroyWeb gros...  {\"Needs Review\"}   \n",
       "\n",
       "      bc_product_id                                              Style  \\\n",
       "48974          NULL                                boho, casual, retro   \n",
       "48975          NULL  androgynous, athleisure, casual, modern, romantic   \n",
       "48976          NULL                        boho, classic, edgy, modern   \n",
       "48977          NULL          androgynous, boho, classic, modern, retro   \n",
       "48978          NULL                                             modern   \n",
       "\n",
       "                                   Occasion                  Category  \n",
       "48974       day to night, vacation, weekend  blazers, coats & jackets  \n",
       "48975      day to night, night out, weekend                    bottom  \n",
       "48976  day to night, weekend, work, workout                   sweater  \n",
       "48977                 day to night, weekend                    bottom  \n",
       "48978                               weekend       sweatshirt & hoodie  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('DSO 560 Project Part I - Final Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '5'></a>\n",
    "\n",
    "# V. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will include all the other models we tried in order to get a best one. For all the models here, we're taking `androgynous` in style as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '51'></a>\n",
    "\n",
    "## 1. LSTM Algorithm Exploration & Parameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some of the parameter tuning, due to limit of time & resource, we could only do very small part of the whole project's algorithms. To keep the whole notebook neat and clean, we only show some of the results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different number of nodes on dense layer, choose number of nodes = 8:**<br>\n",
    "nolayer =========================<br>\n",
    "acc: 0.738919<br>\n",
    "precision: 0.657784<br>\n",
    "recall: 0.726027<br>\n",
    "auc: 0.793065<br>\n",
    "4 =========================<br>\n",
    "acc: 0.740541<br>\n",
    "precision: 0.689683<br>\n",
    "recall: 0.626027<br>\n",
    "auc: 0.794998<br>\n",
    "6 =========================<br>\n",
    "acc: 0.735135<br>\n",
    "precision: 0.665959<br>\n",
    "recall: 0.682192<br>\n",
    "auc: 0.793408<br>\n",
    "8 =========================<br>\n",
    "acc: 0.744054<br>\n",
    "precision: 0.682210<br>\n",
    "recall: 0.673973<br>\n",
    "auc: 0.801046<br>\n",
    "12 =========================<br>\n",
    "acc: 0.739730<br>\n",
    "precision: 0.681197<br>\n",
    "recall: 0.651370<br>\n",
    "auc: 0.791249<br>\n",
    "20 =========================<br>\n",
    "acc: 0.740360<br>\n",
    "precision: 0.678781<br>\n",
    "recall: 0.661187<br>\n",
    "auc: 0.790431<br>\n",
    "28 =========================<br>\n",
    "acc: 0.739730<br>\n",
    "precision: 0.675626<br>\n",
    "recall: 0.665753<br>\n",
    "auc: 0.787420<br>\n",
    "36 =========================<br>\n",
    "acc: 0.737297<br>\n",
    "precision: 0.673547<br>\n",
    "recall: 0.657808<br>\n",
    "auc: 0.785856<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To deal with imbalanced data set, we tried to subset different size of data set labeled as 0 (for the number of samples labeled as 1 is always much smaller), the numbers here mean X times of the samples with label 1:**<br>\n",
    "1.0 =========================<br>\n",
    "acc: 0.706081<br>\n",
    "precision: 0.616230<br>\n",
    "recall: 0.772131<br>\n",
    "auc: 0.774053<br>\n",
    "1.1 =========================<br>\n",
    "acc: 0.716266<br>\n",
    "precision: 0.611659<br>\n",
    "recall: 0.775721<br>\n",
    "auc: 0.777126<br>\n",
    "1.2 =========================<br>\n",
    "acc: 0.717388<br>\n",
    "precision: 0.632041<br>\n",
    "recall: 0.773592<br>\n",
    "auc: 0.781342<br>\n",
    "1.3 =========================<br>\n",
    "acc: 0.722453<br>\n",
    "precision: 0.660609<br>\n",
    "recall: 0.742694<br>\n",
    "auc: 0.796705<br>\n",
    "1.4 =========================<br>\n",
    "acc: 0.726277<br>\n",
    "precision: 0.670427<br>\n",
    "recall: 0.716408<br>\n",
    "auc: 0.800644<br>\n",
    "1.5 =========================<br>\n",
    "acc: 0.727213<br>\n",
    "precision: 0.668327<br>\n",
    "recall: 0.711847<br>\n",
    "auc: 0.801173<br>\n",
    "1.6 =========================<br>\n",
    "acc: 0.728310<br>\n",
    "precision: 0.669492<br>\n",
    "recall: 0.702072<br>\n",
    "auc: 0.801407<br>\n",
    "1.7 =========================<br>\n",
    "acc: 0.730022<br>\n",
    "precision: 0.670665<br>\n",
    "recall: 0.691813<br>\n",
    "auc: 0.802030<br>\n",
    "1.8 =========================<br>\n",
    "acc: 0.732322<br>\n",
    "precision: 0.677012<br>\n",
    "recall: 0.679112<br>\n",
    "auc: 0.801379<br>\n",
    "1.9 =========================<br>\n",
    "acc: 0.734183<br>\n",
    "precision: 0.676259<br>\n",
    "recall: 0.672239<br>\n",
    "auc: 0.800903<br>\n",
    "2.0 =========================<br>\n",
    "acc: 0.736645<br>\n",
    "precision: 0.673135<br>\n",
    "recall: 0.673309<br>\n",
    "auc: 0.801277<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '52'></a>\n",
    "\n",
    "## 2. Neural Net Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10971, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>tag_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>modern</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>business casual</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_value                                           tag_info\n",
       "2           modern  a.l.c lennox high waist cotton linen pant high...\n",
       "3  business casual  a.l.c lennox high waist cotton linen pant high...\n",
       "4          classic  a.l.c lennox high waist cotton linen pant high..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_df = join_data[join_data['attribute_name']=='style'][['attribute_value','tag_info']].drop_duplicates()\n",
    "print(style_df.shape)\n",
    "style_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>tag_info</th>\n",
       "      <th>label_androgynous</th>\n",
       "      <th>label_athleisure</th>\n",
       "      <th>label_boho</th>\n",
       "      <th>label_business casual</th>\n",
       "      <th>label_casual</th>\n",
       "      <th>label_classic</th>\n",
       "      <th>label_edgy</th>\n",
       "      <th>label_glam</th>\n",
       "      <th>label_modern</th>\n",
       "      <th>label_retro</th>\n",
       "      <th>label_romantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>modern</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>business casual</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>classic</td>\n",
       "      <td>a.l.c lennox high waist cotton linen pant high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_value                                           tag_info  \\\n",
       "2           modern  a.l.c lennox high waist cotton linen pant high...   \n",
       "3  business casual  a.l.c lennox high waist cotton linen pant high...   \n",
       "4          classic  a.l.c lennox high waist cotton linen pant high...   \n",
       "\n",
       "   label_androgynous  label_athleisure  label_boho  label_business casual  \\\n",
       "2                  0                 0           0                      0   \n",
       "3                  0                 0           0                      1   \n",
       "4                  0                 0           0                      0   \n",
       "\n",
       "   label_casual  label_classic  label_edgy  label_glam  label_modern  \\\n",
       "2             0              0           0           0             1   \n",
       "3             0              0           0           0             0   \n",
       "4             0              1           0           0             0   \n",
       "\n",
       "   label_retro  label_romantic  \n",
       "2            0               0  \n",
       "3            0               0  \n",
       "4            0               0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the labels\n",
    "label_df = pd.get_dummies(style_df['attribute_value'], prefix='label')\n",
    "model_df = pd.concat([style_df, label_df], axis=1, sort=False)\n",
    "model_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = model_df[model_df['label_androgynous']==1][['tag_info','label_androgynous']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = model_df[model_df['label_androgynous']==0][['tag_info','label_androgynous']].drop_duplicates().sample(model_df['label_androgynous'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_info</th>\n",
       "      <th>label_androgynous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>simon miller rost belted short cinched natural...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593</td>\n",
       "      <td>tibi juan embossed mule tibi juan embossed mul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>khaite leather ankle boot heel measure approxi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>lauren manoogian alpaca-blend scarf brown alpa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1166</td>\n",
       "      <td>carolina herrera pleated stretch-denim wide-le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133887</td>\n",
       "      <td>anine bing charlie boot classic rocker boot bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143794</td>\n",
       "      <td>tory burch kira chevron quilted leather clutch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152855</td>\n",
       "      <td>mansur gavriel cloud lambskin clutch supple la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150636</td>\n",
       "      <td>sam edelman odila sandal scalloped strap toe d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91835</td>\n",
       "      <td>ganni leopard print asymmetrical denim wrap sk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag_info  label_androgynous\n",
       "149     simon miller rost belted short cinched natural...                  1\n",
       "593     tibi juan embossed mule tibi juan embossed mul...                  1\n",
       "772     khaite leather ankle boot heel measure approxi...                  1\n",
       "846     lauren manoogian alpaca-blend scarf brown alpa...                  1\n",
       "1166    carolina herrera pleated stretch-denim wide-le...                  1\n",
       "...                                                   ...                ...\n",
       "133887  anine bing charlie boot classic rocker boot bo...                  0\n",
       "143794  tory burch kira chevron quilted leather clutch...                  0\n",
       "152855  mansur gavriel cloud lambskin clutch supple la...                  0\n",
       "150636  sam edelman odila sandal scalloped strap toe d...                  0\n",
       "91835   ganni leopard print asymmetrical denim wrap sk...                  0\n",
       "\n",
       "[1476 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andro = label_1.append(label_0)\n",
    "andro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = andro.tag_info\n",
    "labels = andro.label_androgynous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs, labels, test_size=0.1, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "max_length = get_max_token_length_per_doc(docs)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Encode the Documents\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "encoded_docs = integer_encode_documents(X_train, tokenizer)\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 7178 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = int(len(tokenizer.word_index) * 1.3)\n",
    "print(f\"Vocab size is {vocab_size} unique tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 100\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 169, 100)          717800    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16900)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16901     \n",
      "=================================================================\n",
      "Total params: 734,701\n",
      "Trainable params: 734,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define and Compile the Model\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "model.add(Flatten()) \n",
    "# for each document, the output of the embedding layer is 4 x 8 matrix\n",
    "# (4 since 4 words per document, 8 since size 8 embedding). Flatten makes this a 32 x 1 vector.\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "# these 32 elements are coalesced into one final output node, a sigmoid\n",
    "# that outputs a probability of positive or negative\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1328/1328 [==============================] - 1s 667us/step - loss: 0.6970 - acc: 0.5060\n",
      "Epoch 2/50\n",
      "1328/1328 [==============================] - 0s 365us/step - loss: 0.6046 - acc: 0.7696\n",
      "Epoch 3/50\n",
      "1328/1328 [==============================] - 0s 363us/step - loss: 0.4787 - acc: 0.8230\n",
      "Epoch 4/50\n",
      "1328/1328 [==============================] - 0s 375us/step - loss: 0.3626 - acc: 0.8660\n",
      "Epoch 5/50\n",
      "1328/1328 [==============================] - 0s 363us/step - loss: 0.2791 - acc: 0.8795\n",
      "Epoch 6/50\n",
      "1328/1328 [==============================] - 1s 409us/step - loss: 0.2307 - acc: 0.8870\n",
      "Epoch 7/50\n",
      "1328/1328 [==============================] - 0s 376us/step - loss: 0.2053 - acc: 0.8810\n",
      "Epoch 8/50\n",
      "1328/1328 [==============================] - 1s 386us/step - loss: 0.1910 - acc: 0.8878\n",
      "Epoch 9/50\n",
      "1328/1328 [==============================] - 0s 367us/step - loss: 0.1816 - acc: 0.8870\n",
      "Epoch 10/50\n",
      "1328/1328 [==============================] - 0s 367us/step - loss: 0.1757 - acc: 0.8901\n",
      "Epoch 11/50\n",
      "1328/1328 [==============================] - 0s 370us/step - loss: 0.1732 - acc: 0.8735\n",
      "Epoch 12/50\n",
      "1328/1328 [==============================] - 0s 369us/step - loss: 0.1658 - acc: 0.8863\n",
      "Epoch 13/50\n",
      "1328/1328 [==============================] - 0s 367us/step - loss: 0.1651 - acc: 0.8863\n",
      "Epoch 14/50\n",
      "1328/1328 [==============================] - 0s 373us/step - loss: 0.1626 - acc: 0.8886\n",
      "Epoch 15/50\n",
      "1328/1328 [==============================] - 1s 388us/step - loss: 0.1637 - acc: 0.8870\n",
      "Epoch 16/50\n",
      "1328/1328 [==============================] - 1s 401us/step - loss: 0.1584 - acc: 0.8916\n",
      "Epoch 17/50\n",
      "1328/1328 [==============================] - 1s 406us/step - loss: 0.1619 - acc: 0.8901\n",
      "Epoch 18/50\n",
      "1328/1328 [==============================] - 1s 421us/step - loss: 0.1568 - acc: 0.8901\n",
      "Epoch 19/50\n",
      "1328/1328 [==============================] - 0s 356us/step - loss: 0.1568 - acc: 0.8901\n",
      "Epoch 20/50\n",
      "1328/1328 [==============================] - 1s 400us/step - loss: 0.1556 - acc: 0.8901\n",
      "Epoch 21/50\n",
      "1328/1328 [==============================] - 0s 374us/step - loss: 0.1559 - acc: 0.8886\n",
      "Epoch 22/50\n",
      "1328/1328 [==============================] - 1s 378us/step - loss: 0.1539 - acc: 0.8825\n",
      "Epoch 23/50\n",
      "1328/1328 [==============================] - 1s 385us/step - loss: 0.1537 - acc: 0.8878\n",
      "Epoch 24/50\n",
      "1328/1328 [==============================] - 0s 372us/step - loss: 0.1518 - acc: 0.8908\n",
      "Epoch 25/50\n",
      "1328/1328 [==============================] - 0s 355us/step - loss: 0.1532 - acc: 0.8893\n",
      "Epoch 26/50\n",
      "1328/1328 [==============================] - 0s 358us/step - loss: 0.1489 - acc: 0.8923\n",
      "Epoch 27/50\n",
      "1328/1328 [==============================] - 0s 355us/step - loss: 0.1499 - acc: 0.8840\n",
      "Epoch 28/50\n",
      "1328/1328 [==============================] - 0s 353us/step - loss: 0.1502 - acc: 0.8840\n",
      "Epoch 29/50\n",
      "1328/1328 [==============================] - 0s 364us/step - loss: 0.1494 - acc: 0.8893\n",
      "Epoch 30/50\n",
      "1328/1328 [==============================] - 1s 412us/step - loss: 0.1523 - acc: 0.8780\n",
      "Epoch 31/50\n",
      "1328/1328 [==============================] - 0s 360us/step - loss: 0.1488 - acc: 0.8901\n",
      "Epoch 32/50\n",
      "1328/1328 [==============================] - 1s 384us/step - loss: 0.1473 - acc: 0.8810\n",
      "Epoch 33/50\n",
      "1328/1328 [==============================] - 0s 361us/step - loss: 0.1483 - acc: 0.8938\n",
      "Epoch 34/50\n",
      "1328/1328 [==============================] - 0s 366us/step - loss: 0.1482 - acc: 0.8825\n",
      "Epoch 35/50\n",
      "1328/1328 [==============================] - 0s 364us/step - loss: 0.1463 - acc: 0.8878\n",
      "Epoch 36/50\n",
      "1328/1328 [==============================] - 1s 389us/step - loss: 0.1472 - acc: 0.8886\n",
      "Epoch 37/50\n",
      "1328/1328 [==============================] - 1s 443us/step - loss: 0.1463 - acc: 0.8886\n",
      "Epoch 38/50\n",
      "1328/1328 [==============================] - 1s 421us/step - loss: 0.1460 - acc: 0.8840\n",
      "Epoch 39/50\n",
      "1328/1328 [==============================] - 1s 425us/step - loss: 0.1471 - acc: 0.8848\n",
      "Epoch 40/50\n",
      "1328/1328 [==============================] - 1s 432us/step - loss: 0.1464 - acc: 0.8893\n",
      "Epoch 41/50\n",
      "1328/1328 [==============================] - 1s 411us/step - loss: 0.1459 - acc: 0.8818\n",
      "Epoch 42/50\n",
      "1328/1328 [==============================] - 1s 435us/step - loss: 0.1443 - acc: 0.8855\n",
      "Epoch 43/50\n",
      "1328/1328 [==============================] - 1s 427us/step - loss: 0.1440 - acc: 0.8901\n",
      "Epoch 44/50\n",
      "1328/1328 [==============================] - 1s 377us/step - loss: 0.1450 - acc: 0.8855\n",
      "Epoch 45/50\n",
      "1328/1328 [==============================] - 1s 425us/step - loss: 0.1429 - acc: 0.8870\n",
      "Epoch 46/50\n",
      "1328/1328 [==============================] - 1s 410us/step - loss: 0.1438 - acc: 0.8818\n",
      "Epoch 47/50\n",
      "1328/1328 [==============================] - 1s 414us/step - loss: 0.1454 - acc: 0.8855\n",
      "Epoch 48/50\n",
      "1328/1328 [==============================] - 1s 386us/step - loss: 0.1432 - acc: 0.8803\n",
      "Epoch 49/50\n",
      "1328/1328 [==============================] - 1s 417us/step - loss: 0.1436 - acc: 0.8893\n",
      "Epoch 50/50\n",
      "1328/1328 [==============================] - 1s 397us/step - loss: 0.1427 - acc: 0.8848\n",
      "1328/1328 [==============================] - 0s 73us/step\n",
      "Accuracy: 91.867470\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, y_train, epochs=50,verbose=1)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, y_train, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.864865\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "encoded_test_docs = integer_encode_documents(X_test, tokenizer)\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "prediction = model.predict_classes(padded_test_docs, verbose=0) # there's also presict_classes\n",
    "loss, accuracy = model.evaluate(padded_test_docs, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.13 55.7\n"
     ]
    }
   ],
   "source": [
    "# Get recall and precision\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "recall = recall_score(y_test, prediction)\n",
    "precision = precision_score(y_test, prediction)\n",
    "print(round(recall*100,2),round(precision*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = '53'></a>\n",
    "\n",
    "## 3. Pre-trained Word Embedding & TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Style = join_data[join_data['attribute_name']=='style'][['tag_info', 'attribute_value']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Style['tag_info'], Style['attribute_value'], test_size=0.1, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# load spacy en_core_web_md model\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuart weitzman nearlynude suede sandal heel measure approximately 65mm/ 2.5 inch black suede buckle-fastening ankle strap made spain shoe sandal mid heel fit true size take normal size italian sizing\n",
      "[-0.04354022  0.22852366 -0.08482351 -0.03297778  0.21501721 -0.08279714\n",
      " -0.09283376  0.04464567  0.02363911  0.7117972 ]\n",
      "cotton citizen sydney crewneck tee la-based label latest crop elevated staple slouchy tee get luxuriously soft feel blend supima® cotton micromodal unknown true size xs=0-2 s=4-6 m=8-10 l=12-14.27 1/2 length size medium crewneckelbow-length sleeves50 % supima cotton 50 % micromodalmachine wash tumble drymade usavia c\n",
      "[-0.07908691  0.28327072 -0.0611436  -0.05602018  0.03003889 -0.00633907\n",
      "  0.02156887 -0.02853958 -0.06940804  0.7416781 ]\n",
      "allsaints keri cyla shirt airy split-collar blouse detailed delicate bloom easy day-to-night charm unknown true size xs=00-0 s=2-4 m=6-8 l=10.26 1/2 length size medium split neck spread collarlong sleeves100 % viscosehand wash line dryimportedt.b.d\n",
      "[-0.06788526  0.26872906 -0.06337402  0.06618493  0.0313492  -0.05150024\n",
      " -0.00383163  0.04055135  0.00415936  0.9008799 ]\n",
      "j.crew garment washed crewneck sweater look little closer ribbed sweater detail detail due special fading process unknown true size xxs=00 xs=0-2 s=4-6 m=8-10 l=12-14 xl=16 xxl=18 16w 2x=20 18w-20w 3x=22-24 22w-24w\n",
      "[-0.02737468  0.2059439  -0.07955421  0.09203439  0.02300278 -0.01401683\n",
      "  0.07777966 -0.00646912 -0.0528264   0.80971575]\n"
     ]
    }
   ],
   "source": [
    "for idx, info in enumerate(X_train):\n",
    "    print(nlp(info))\n",
    "    print(nlp(info).vector[:10]) \n",
    "    \n",
    "    if idx == 3: # stop printing after first 5 or so, takes a long time!\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([Style['tag_info'], pd.Series(stylelist)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10962    atm anthony thomas melillo brushed twill crop ...\n",
       "10963    atm anthony thomas melillo slim crop pant tail...\n",
       "10964    atm anthony thomas melillo slim crop pant tail...\n",
       "10965    atm anthony thomas melillo slim crop pant tail...\n",
       "10966    atm anthony thomas melillo camo print silk ski...\n",
       "10967    atm anthony thomas melillo camo print silk ski...\n",
       "10968    atm anthony thomas melillo camo print silk ski...\n",
       "10969    atm anthony thomas melillo stretch pima cotton...\n",
       "10970    atm anthony thomas melillo stretch pima cotton...\n",
       "10971                                          androgynous\n",
       "10972                                      athlete leisure\n",
       "10973                                                 boho\n",
       "10974                                      business casual\n",
       "10975                                               casual\n",
       "10976                                              classic\n",
       "10977                                                 edgy\n",
       "10978                                                 glam\n",
       "10979                                               modern\n",
       "10980                                                retro\n",
       "10981                                             romantic\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "tf_idf_lookup_table = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_SUM_COLUMN = \"DOCUMENT_TF_IDF_SUM\"\n",
    "\n",
    "# sum the tf idf scores for each document\n",
    "tf_idf_lookup_table[DOCUMENT_SUM_COLUMN] = tf_idf_lookup_table.sum(axis=1)\n",
    "available_tf_idf_scores = tf_idf_lookup_table.columns # a list of all the columns we have\n",
    "available_tf_idf_scores = list(map( lambda x: x.lower(), available_tf_idf_scores)) # lowercase everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_info_vectors = []\n",
    "for idx, info in enumerate(all_data): # iterate through each review\n",
    "    tokens = nlp(info) # have spacy tokenize the review text\n",
    "    \n",
    "    # initially start a running total of tf-idf scores for a document\n",
    "    total_tf_idf_score_per_document = 0\n",
    "    \n",
    "    # start a running total of initially all zeroes (300 is picked since that is the word embedding size used by word2vec)\n",
    "    running_total_word_embedding = np.zeros(300) \n",
    "    for token in tokens: # iterate through each token\n",
    "    \n",
    "    # if the token has a pretrained word embedding it also has a tf-idf score\n",
    "        if token.has_vector and token.text.lower() in available_tf_idf_scores:\n",
    "            \n",
    "            tf_idf_score = tf_idf_lookup_table.loc[idx, token.text.lower()]\n",
    "            #print(f\"{token} has tf-idf score of {tf_idf_lookup_table.loc[idx, token.text.lower()]}\")\n",
    "            running_total_word_embedding += tf_idf_score * token.vector\n",
    "            \n",
    "            total_tf_idf_score_per_document += tf_idf_score\n",
    "    \n",
    "    # divide the total embedding by the total tf-idf score for each document\n",
    "    document_embedding = running_total_word_embedding / total_tf_idf_score_per_document\n",
    "    tag_info_vectors.append(document_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = pd.DataFrame(cosine_similarity(tag_info_vectors), columns=list(range(len(all_data))), index=list(range(len(all_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = similarities.unstack().reset_index()\n",
    "similarities.columns = [\"info1\", \"info2\", \"similarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.872394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.872394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120604319</th>\n",
       "      <td>10981</td>\n",
       "      <td>10977</td>\n",
       "      <td>0.436875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120604320</th>\n",
       "      <td>10981</td>\n",
       "      <td>10978</td>\n",
       "      <td>0.244309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120604321</th>\n",
       "      <td>10981</td>\n",
       "      <td>10979</td>\n",
       "      <td>0.420758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120604322</th>\n",
       "      <td>10981</td>\n",
       "      <td>10980</td>\n",
       "      <td>0.314959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120604323</th>\n",
       "      <td>10981</td>\n",
       "      <td>10981</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120604324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           info1  info2  similarity\n",
       "0              0      0    1.000000\n",
       "1              0      1    1.000000\n",
       "2              0      2    1.000000\n",
       "3              0      3    0.872394\n",
       "4              0      4    0.872394\n",
       "...          ...    ...         ...\n",
       "120604319  10981  10977    0.436875\n",
       "120604320  10981  10978    0.244309\n",
       "120604321  10981  10979    0.420758\n",
       "120604322  10981  10980    0.314959\n",
       "120604323  10981  10981    1.000000\n",
       "\n",
       "[120604324 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore androgynous\n",
    "androgynous_list = list(y_train[y_train == 'androgynous'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>665.0</td>\n",
       "      <td>665.000000</td>\n",
       "      <td>665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>4606.088722</td>\n",
       "      <td>0.457646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3097.731370</td>\n",
       "      <td>0.056341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.192040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>1767.000000</td>\n",
       "      <td>0.423134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>4581.000000</td>\n",
       "      <td>0.456298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>7410.000000</td>\n",
       "      <td>0.498161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>10745.000000</td>\n",
       "      <td>0.614389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2  similarity\n",
       "count    665.0    665.000000  665.000000\n",
       "mean   10971.0   4606.088722    0.457646\n",
       "std        0.0   3097.731370    0.056341\n",
       "min    10971.0      7.000000    0.192040\n",
       "25%    10971.0   1767.000000    0.423134\n",
       "50%    10971.0   4581.000000    0.456298\n",
       "75%    10971.0   7410.000000    0.498161\n",
       "max    10971.0  10745.000000    0.614389"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "androgynous_sample = similarities[similarities['info1']==10971].iloc[androgynous_list,]\n",
    "androgynous_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10306.0</td>\n",
       "      <td>10306.000000</td>\n",
       "      <td>10306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>5541.712206</td>\n",
       "      <td>0.466153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3163.400186</td>\n",
       "      <td>0.058780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>2832.250000</td>\n",
       "      <td>0.430364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>5548.500000</td>\n",
       "      <td>0.466920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>8257.750000</td>\n",
       "      <td>0.506311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>10970.000000</td>\n",
       "      <td>0.682295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2    similarity\n",
       "count  10306.0  10306.000000  10306.000000\n",
       "mean   10971.0   5541.712206      0.466153\n",
       "std        0.0   3163.400186      0.058780\n",
       "min    10971.0      0.000000      0.192040\n",
       "25%    10971.0   2832.250000      0.430364\n",
       "50%    10971.0   5548.500000      0.466920\n",
       "75%    10971.0   8257.750000      0.506311\n",
       "max    10971.0  10970.000000      0.682295"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_androgynous_sample = similarities[similarities['info1']==10971].iloc[[idx for idx in list(range(10971)) if idx not in androgynous_list],]\n",
    "not_androgynous_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.07473812612260322, pvalue=0.0018628637866398231)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.ks_2samp(not_androgynous_sample['similarity'], androgynous_sample['similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore athlete leisure\n",
    "athleisure_list = list(y_train[y_train == 'athlete leisure'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>246.0</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>3533.573171</td>\n",
       "      <td>0.402090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1770.842150</td>\n",
       "      <td>0.060444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.196396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>3044.250000</td>\n",
       "      <td>0.363659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>3623.000000</td>\n",
       "      <td>0.403139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>3836.750000</td>\n",
       "      <td>0.439140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>10957.000000</td>\n",
       "      <td>0.568066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2  similarity\n",
       "count    246.0    246.000000  246.000000\n",
       "mean   10972.0   3533.573171    0.402090\n",
       "std        0.0   1770.842150    0.060444\n",
       "min    10972.0     68.000000    0.196396\n",
       "25%    10972.0   3044.250000    0.363659\n",
       "50%    10972.0   3623.000000    0.403139\n",
       "75%    10972.0   3836.750000    0.439140\n",
       "max    10972.0  10957.000000    0.568066"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athleisure_sample = similarities[similarities['info1']==10972].iloc[athleisure_list,]\n",
    "athleisure_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10725.0</td>\n",
       "      <td>10725.000000</td>\n",
       "      <td>10725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>5529.760000</td>\n",
       "      <td>0.353746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3178.090265</td>\n",
       "      <td>0.052925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.319128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>5583.000000</td>\n",
       "      <td>0.354208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>8283.000000</td>\n",
       "      <td>0.389327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10972.0</td>\n",
       "      <td>10970.000000</td>\n",
       "      <td>0.568066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2    similarity\n",
       "count  10725.0  10725.000000  10725.000000\n",
       "mean   10972.0   5529.760000      0.353746\n",
       "std        0.0   3178.090265      0.052925\n",
       "min    10972.0      0.000000      0.155797\n",
       "25%    10972.0   2734.000000      0.319128\n",
       "50%    10972.0   5583.000000      0.354208\n",
       "75%    10972.0   8283.000000      0.389327\n",
       "max    10972.0  10970.000000      0.568066"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_athleisure_sample = similarities[similarities['info1']==10972].iloc[[idx for idx in list(range(10971)) if idx not in athleisure_list],]\n",
    "not_athleisure_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.36119392802319633, pvalue=1.1222681682684779e-27)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ks_2samp(not_athleisure_sample['similarity'], athleisure_sample['similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore causal\n",
    "casual_list = list(y_train[y_train == 'casual'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2414.0</td>\n",
       "      <td>2414.000000</td>\n",
       "      <td>2414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>5972.966446</td>\n",
       "      <td>0.479393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2997.034671</td>\n",
       "      <td>0.051730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.209873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>3704.500000</td>\n",
       "      <td>0.449337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>5865.500000</td>\n",
       "      <td>0.482379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>8548.750000</td>\n",
       "      <td>0.513309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>10967.000000</td>\n",
       "      <td>0.645260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2   similarity\n",
       "count   2414.0   2414.000000  2414.000000\n",
       "mean   10975.0   5972.966446     0.479393\n",
       "std        0.0   2997.034671     0.051730\n",
       "min    10975.0      6.000000     0.209873\n",
       "25%    10975.0   3704.500000     0.449337\n",
       "50%    10975.0   5865.500000     0.482379\n",
       "75%    10975.0   8548.750000     0.513309\n",
       "max    10975.0  10967.000000     0.645260"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casual_sample = similarities[similarities['info1']==10975].iloc[casual_list,]\n",
    "casual_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info1</th>\n",
       "      <th>info2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8557.0</td>\n",
       "      <td>8557.000000</td>\n",
       "      <td>8557.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>5347.340657</td>\n",
       "      <td>0.483250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.314836</td>\n",
       "      <td>0.050730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>2493.000000</td>\n",
       "      <td>0.452230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>5295.000000</td>\n",
       "      <td>0.484557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>8129.000000</td>\n",
       "      <td>0.516709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10975.0</td>\n",
       "      <td>10970.000000</td>\n",
       "      <td>0.645260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         info1         info2   similarity\n",
       "count   8557.0   8557.000000  8557.000000\n",
       "mean   10975.0   5347.340657     0.483250\n",
       "std        0.0   3200.314836     0.050730\n",
       "min    10975.0      0.000000     0.209873\n",
       "25%    10975.0   2493.000000     0.452230\n",
       "50%    10975.0   5295.000000     0.484557\n",
       "75%    10975.0   8129.000000     0.516709\n",
       "max    10975.0  10970.000000     0.645260"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_casual_sample = similarities[similarities['info1']==10975].iloc[[idx for idx in list(range(10971)) if idx not in casual_list],]\n",
    "not_casual_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.031677239398278455, pvalue=1.0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ks_2samp(not_casual_sample['similarity'], casual_sample['similarity'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
